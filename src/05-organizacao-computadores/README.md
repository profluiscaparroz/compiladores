# 05 â€” OrganizaÃ§Ã£o de Computadores no Contexto de Compiladores

## ğŸ“š Ãndice

1. [IntroduÃ§Ã£o e Objetivos](#introduÃ§Ã£o-e-objetivos)
2. [Fundamentos TeÃ³ricos](#fundamentos-teÃ³ricos)
3. [Arquitetura de von Neumann](#arquitetura-de-von-neumann)
4. [A CPU e Seus Componentes](#a-cpu-e-seus-componentes)
5. [Registradores](#registradores)
6. [MemÃ³ria e Hierarquia](#memÃ³ria-e-hierarquia)
7. [Conjunto de InstruÃ§Ãµes (ISA)](#conjunto-de-instruÃ§Ãµes-isa)
8. [Modos de EndereÃ§amento](#modos-de-endereÃ§amento)
9. [Pipeline e Paralelismo](#pipeline-e-paralelismo)
10. [ConvenÃ§Ãµes de Chamada de FunÃ§Ã£o](#convenÃ§Ãµes-de-chamada-de-funÃ§Ã£o)
11. [CompilaÃ§Ã£o e GeraÃ§Ã£o de CÃ³digo](#compilaÃ§Ã£o-e-geraÃ§Ã£o-de-cÃ³digo)
12. [Arquiteturas RISC vs CISC](#arquiteturas-risc-vs-cisc)
13. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
14. [ExercÃ­cios AcadÃªmicos](#exercÃ­cios-acadÃªmicos)
15. [Perguntas para Pensar](#perguntas-para-pensar)
16. [ReferÃªncias e Leitura Adicional](#referÃªncias-e-leitura-adicional)

---

## IntroduÃ§Ã£o e Objetivos

### ğŸ¯ Objetivos de Aprendizagem

- **Compreender** a ponte fundamental entre compilaÃ§Ã£o e arquitetura de computadores
- **Dominar** conceitos de registradores, memÃ³ria e conjunto de instruÃ§Ãµes
- **Relacionar** a geraÃ§Ã£o de cÃ³digo com caracterÃ­sticas especÃ­ficas da arquitetura alvo
- **Analisar** como decisÃµes de design de arquitetura impactam o trabalho do compilador
- **Implementar** traduÃ§Ãµes de cÃ³digo de alto nÃ­vel para assembly
- **Otimizar** cÃ³digo considerando caracterÃ­sticas do hardware

### ğŸ”— Por Que OrganizaÃ§Ã£o de Computadores Ã© Essencial para Compiladores?

Um compilador Ã©, essencialmente, um **tradutor** que converte linguagens de alto nÃ­vel em instruÃ§Ãµes de mÃ¡quina. Para fazer isso eficientemente, o compilador precisa:

1. **Conhecer a arquitetura alvo**: Quantos registradores existem? Quais instruÃ§Ãµes estÃ£o disponÃ­veis?
2. **Entender custos**: Algumas operaÃ§Ãµes sÃ£o mais caras que outras (divisÃ£o vs. multiplicaÃ§Ã£o, acesso Ã  memÃ³ria vs. registrador)
3. **Explorar caracterÃ­sticas**: Pipeline, cache, paralelismo em nÃ­vel de instruÃ§Ã£o (ILP)
4. **Respeitar convenÃ§Ãµes**: ABIs (Application Binary Interfaces), calling conventions

Sem entender a organizaÃ§Ã£o do computador, um compilador geraria cÃ³digo **correto mas ineficiente**.

---

## Fundamentos TeÃ³ricos

### ğŸ§  O Modelo Abstrato de MÃ¡quina

Historicamente, o conceito de "mÃ¡quina" na computaÃ§Ã£o tem raÃ­zes teÃ³ricas profundas:

#### MÃ¡quina de Turing (1936)
Alan Turing propÃ´s um modelo abstrato com:
- **Fita infinita** (memÃ³ria)
- **CabeÃ§ote de leitura/escrita**
- **Conjunto finito de estados**
- **FunÃ§Ã£o de transiÃ§Ã£o**

Este modelo estabelece os **limites teÃ³ricos da computaÃ§Ã£o** â€” o que Ã© computÃ¡vel.

#### Arquitetura de von Neumann (1945)
John von Neumann propÃ´s uma arquitetura prÃ¡tica baseada em:
- **Programa armazenado**: InstruÃ§Ãµes e dados na mesma memÃ³ria
- **Processamento sequencial**: Uma instruÃ§Ã£o por vez (ciclo fetch-decode-execute)
- **Barramentos compartilhados**: ComunicaÃ§Ã£o entre componentes

**DiferenÃ§a chave**: A MÃ¡quina de Turing Ã© um modelo **teÃ³rico** (fita infinita), enquanto von Neumann Ã© uma arquitetura **prÃ¡tica** (memÃ³ria finita, implementÃ¡vel em hardware).

### ğŸ”„ Do Abstrato ao Concreto

```
MÃ¡quina de Turing (Abstrata)
        â†“
Arquitetura de von Neumann (Modelo)
        â†“
x86, ARM, RISC-V, MIPS (ImplementaÃ§Ãµes)
        â†“
Intel Core i7, AMD Ryzen, Apple M1 (Hardware Real)
```

Um **compilador** precisa traduzir programas para **arquiteturas concretas**, mas usa princÃ­pios teÃ³ricos para garantir correÃ§Ã£o.

---

## Arquitetura de von Neumann

### ğŸ“ Componentes Principais

A arquitetura de von Neumann consiste em 5 componentes fundamentais:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  INPUT   â”‚â”€â”€â”€â”€â”€â–¶â”‚                   â”‚           â”‚
â”‚  â”‚ DEVICES  â”‚      â”‚                   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      MEMÃ“RIA      â”‚           â”‚
â”‚                    â”‚     PRINCIPAL     â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    (RAM/ROM)      â”‚           â”‚
â”‚  â”‚  OUTPUT  â”‚â—€â”€â”€â”€â”€â”€â”‚                   â”‚           â”‚
â”‚  â”‚ DEVICES  â”‚      â”‚                   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                              â”‚                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                    â”‚                   â”‚            â”‚
â”‚                    â”‚     UNIDADE       â”‚            â”‚
â”‚                    â”‚    DE CONTROLE    â”‚            â”‚
â”‚                    â”‚       (UC)        â”‚            â”‚
â”‚                    â”‚                   â”‚            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                              â”‚                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                    â”‚                   â”‚            â”‚
â”‚                    â”‚     UNIDADE       â”‚            â”‚
â”‚                    â”‚   LÃ“GICA E        â”‚            â”‚
â”‚                    â”‚   ARITMÃ‰TICA      â”‚            â”‚
â”‚                    â”‚      (ULA)        â”‚            â”‚
â”‚                    â”‚                   â”‚            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                      â”‚
â”‚                     CPU                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1. **Unidade Central de Processamento (CPU)**
O "cÃ©rebro" que executa instruÃ§Ãµes. Composta por:
- **UC (Unidade de Controle)**: Busca, decodifica e coordena execuÃ§Ã£o
- **ULA (Unidade LÃ³gica e AritmÃ©tica)**: Executa operaÃ§Ãµes matemÃ¡ticas e lÃ³gicas

#### 2. **MemÃ³ria Principal**
Armazena:
- **InstruÃ§Ãµes do programa** (code segment)
- **Dados** (variÃ¡veis, constantes)
- **Stack** (chamadas de funÃ§Ã£o, variÃ¡veis locais)
- **Heap** (alocaÃ§Ã£o dinÃ¢mica)

#### 3. **Dispositivos de Entrada/SaÃ­da**
ComunicaÃ§Ã£o com o mundo externo:
- Entrada: teclado, mouse, sensores
- SaÃ­da: monitor, impressora
- Ambos: disco, rede

#### 4. **Barramentos**
Canais de comunicaÃ§Ã£o que conectam os componentes:
- **Barramento de Dados**: Transporta dados (8, 16, 32, 64 bits)
- **Barramento de EndereÃ§os**: Especifica localizaÃ§Ãµes na memÃ³ria
- **Barramento de Controle**: Sinais de controle (leitura, escrita, interrupÃ§Ãµes)

### ï¿½ï¿½ O Ciclo de InstruÃ§Ã£o (Fetch-Decode-Execute)

Todo processador von Neumann opera em um ciclo fundamental:

```
1. FETCH (Busca)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ PC â”€â”€â–¶ MemÃ³ria â”€â”€â–¶ IR           â”‚
   â”‚ (Busca instruÃ§Ã£o apontada por PC)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
2. DECODE (DecodificaÃ§Ã£o)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ UC interpreta o opcode           â”‚
   â”‚ Identifica operandos             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
3. EXECUTE (ExecuÃ§Ã£o)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ULA executa a operaÃ§Ã£o           â”‚
   â”‚ Ou UC realiza transferÃªncia      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
4. WRITE-BACK (Armazenamento)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Resultado â”€â”€â–¶ Registrador/MemÃ³riaâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
5. UPDATE PC
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ PC = PC + tamanho_da_instruÃ§Ã£o   â”‚
   â”‚ (ou novo endereÃ§o em caso de jump)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        (Volta para FETCH)
```

**Exemplo Concreto**: Executando `ADD R1, R2, R3` (R1 = R2 + R3)

1. **FETCH**: Busca instruÃ§Ã£o da memÃ³ria no endereÃ§o apontado por PC
2. **DECODE**: UC identifica: opcode=ADD, dest=R1, src1=R2, src2=R3
3. **EXECUTE**: ULA soma conteÃºdo de R2 e R3
4. **WRITE-BACK**: Resultado Ã© escrito em R1
5. **UPDATE PC**: PC += 4 (assumindo instruÃ§Ãµes de 32 bits)

### âš¡ Velocidade e Clock

O **clock** determina a velocidade do ciclo:
- **FrequÃªncia**: Medida em Hz (ciclos por segundo)
  - 1 Hz = 1 ciclo/segundo
  - 1 GHz = 1.000.000.000 ciclos/segundo
- **PerÃ­odo**: Tempo de um ciclo = 1/frequÃªncia
  - CPU de 3 GHz: perÃ­odo = 1/3.000.000.000 â‰ˆ 0,33 nanosegundos

**Importante**: Uma instruÃ§Ã£o pode levar **mÃºltiplos ciclos de clock** para executar (especialmente em arquiteturas CISC). Pipeline moderno permite iniciar uma nova instruÃ§Ã£o a cada ciclo.

---

## A CPU e Seus Componentes

### ğŸ§© Anatomia Detalhada da CPU

#### 1. Unidade de Controle (UC)

**Responsabilidades**:
- **Buscar** instruÃ§Ãµes da memÃ³ria
- **Decodificar** instruÃ§Ãµes (interpretar opcode e operandos)
- **Gerar sinais de controle** para coordenar outros componentes
- **Gerenciar** o fluxo de execuÃ§Ã£o (branches, jumps)

**Componentes Internos**:
- **Program Counter (PC)**: Registrador que aponta para a prÃ³xima instruÃ§Ã£o
- **Instruction Register (IR)**: Armazena a instruÃ§Ã£o atual
- **Decodificador**: Circuito lÃ³gico que interpreta opcodes
- **Sequenciador**: Gera sinais de controle na ordem correta

#### 2. Unidade LÃ³gica e AritmÃ©tica (ULA / ALU)

**OperaÃ§Ãµes AritmÃ©ticas**:
- AdiÃ§Ã£o, subtraÃ§Ã£o
- MultiplicaÃ§Ã£o, divisÃ£o (em ALUs mais complexas)
- Incremento, decremento

**OperaÃ§Ãµes LÃ³gicas**:
- AND, OR, XOR, NOT
- Deslocamentos (shift left/right)
- RotaÃ§Ãµes

**OperaÃ§Ãµes de ComparaÃ§Ã£o**:
- Igual, diferente
- Maior, menor, maior ou igual, menor ou igual

**Flags (Registrador de Status)**:
- **Zero (Z)**: Resultado foi zero
- **Carry (C)**: Houve carry-out no bit mais significativo
- **Overflow (V)**: Overflow em aritmÃ©tica com sinal
- **Negative (N)**: Resultado Ã© negativo
- **Parity (P)**: Paridade do resultado

**Exemplo**: AdiÃ§Ã£o 8 + 7 = 15

```
  00001000  (8)
+ 00000111  (7)
-----------
  00001111  (15)

Flags apÃ³s operaÃ§Ã£o:
Z = 0 (resultado nÃ£o Ã© zero)
C = 0 (sem carry)
N = 0 (resultado positivo)
V = 0 (sem overflow)
```

#### 3. Registradores

MemÃ³ria **ultra-rÃ¡pida** dentro da CPU. Explicados em detalhes na prÃ³xima seÃ§Ã£o.

### ğŸ”¬ ImplementaÃ§Ã£o: Microarquitetura

A **arquitetura** define o que o processador faz (ISA visÃ­vel ao programador).
A **microarquitetura** define como ele faz (implementaÃ§Ã£o interna).

**Exemplo**: x86-64 Ã© uma arquitetura. Intel Core, AMD Ryzen sÃ£o microarquiteturas diferentes que implementam x86-64.

Diferentes microarquiteturas podem ter:
- NÃºmero diferente de estÃ¡gios de pipeline
- Caches de tamanhos diferentes
- Unidades de execuÃ§Ã£o diferentes (mÃºltiplas ALUs, FPUs)
- Previsores de branch diferentes

---

## Registradores

### ğŸ“Š O Que SÃ£o Registradores?

Registradores sÃ£o **pequenas memÃ³rias** localizadas **dentro da CPU**, com as seguintes caracterÃ­sticas:

| CaracterÃ­stica | Registrador | Cache L1 | RAM | Disco |
|----------------|-------------|----------|-----|-------|
| **Tamanho** | ~32-256 bytes | ~32-64 KB | GB | TB |
| **Velocidade** | 1 ciclo | 3-4 ciclos | 100+ ciclos | milhÃµes de ciclos |
| **LocalizaÃ§Ã£o** | Dentro da CPU | Na CPU | Fora da CPU | Dispositivo I/O |
| **Custo** | Muito alto | Alto | MÃ©dio | Baixo |

### ğŸ¯ Tipos de Registradores

#### 1. **Registradores de PropÃ³sito Geral (GPR)**

Usados para armazenar dados temporÃ¡rios durante computaÃ§Ãµes.

**Arquitetura x86-64 (64 bits)**:
```
RAX, RBX, RCX, RDX   â† Registradores principais (64 bits)
RSI, RDI              â† Ãndices para strings
R8-R15                â† Registradores adicionais
```

**Compatibilidade com tamanhos menores**:
```
RAX (64 bits) : |--------------------------------|
EAX (32 bits) :                 |----------------|
 AX (16 bits) :                          |------|
 AH (8 bits)  :                          |----|
 AL (8 bits)  :                              |--|
```

**Arquitetura MIPS (32 registradores)**:
```
$zero ($0)   : Sempre contÃ©m 0
$at ($1)     : Reservado para assembler
$v0-$v1      : Valores de retorno
$a0-$a3      : Argumentos de funÃ§Ã£o
$t0-$t9      : TemporÃ¡rios (nÃ£o preservados)
$s0-$s7      : Salvos (devem ser preservados)
$k0-$k1      : Reservados para kernel
$gp          : Global pointer
$sp          : Stack pointer
$fp          : Frame pointer
$ra          : Return address
```

#### 2. **Registradores Especiais**

**Program Counter (PC) / Instruction Pointer (IP)**:
- Armazena o **endereÃ§o da prÃ³xima instruÃ§Ã£o**
- Incrementado automaticamente apÃ³s cada instruÃ§Ã£o
- Modificado por instruÃ§Ãµes de controle (JMP, CALL, RET)

```assembly
; Exemplo de modificaÃ§Ã£o do PC
0x1000: MOV RAX, 42    ; PC = 0x1000
0x1004: ADD RAX, 8     ; PC = 0x1004  
0x1008: JMP 0x2000     ; PC = 0x2000 (salto)
0x2000: SUB RAX, 10    ; PC = 0x2000
```

**Stack Pointer (SP)**:
- Aponta para o **topo da pilha**
- Decrementado em PUSH, incrementado em POP
- Essencial para chamadas de funÃ§Ã£o

```assembly
; Exemplo de operaÃ§Ãµes com pilha
PUSH RAX        ; SP -= 8, [SP] = RAX
PUSH RBX        ; SP -= 8, [SP] = RBX
POP RCX         ; RCX = [SP], SP += 8
```

**Frame Pointer (FP/BP)**:
- Aponta para a **base do frame** da funÃ§Ã£o atual
- Facilita acesso a parÃ¢metros e variÃ¡veis locais
- Em x86-64: RBP

**Status Register / Flags**:
- Armazena **condiÃ§Ãµes** resultantes de operaÃ§Ãµes
- Usado por instruÃ§Ãµes condicionais

#### 3. **Registradores de Ponto Flutuante**

Para operaÃ§Ãµes com nÃºmeros reais:

**x86-64**:
```
XMM0-XMM15  : Registradores SSE (128 bits)
YMM0-YMM15  : Registradores AVX (256 bits)
ZMM0-ZMM31  : Registradores AVX-512 (512 bits)
```

Permitem **SIMD** (Single Instruction, Multiple Data) â€” uma instruÃ§Ã£o processa mÃºltiplos dados:
```assembly
; Somar 4 floats de uma vez
ADDPS XMM0, XMM1   ; XMM0[0-3] += XMM1[0-3]
```

### ğŸª AlocaÃ§Ã£o de Registradores no Compilador

Um dos **problemas mais importantes** na geraÃ§Ã£o de cÃ³digo Ã© decidir **quais variÃ¡veis** ficam em **quais registradores**.

#### Problema da ColoraÃ§Ã£o de Grafos

1. **Construir grafo de interferÃªncia**: NÃ³s sÃ£o variÃ¡veis, arestas conectam variÃ¡veis que estÃ£o "vivas" simultaneamente
2. **Colorir o grafo**: Atribuir cores (registradores) aos nÃ³s tal que nÃ³s adjacentes tenham cores diferentes
3. **Spilling**: Se nÃ£o hÃ¡ registradores suficientes, algumas variÃ¡veis vÃ£o para memÃ³ria

**Exemplo Simples**:
```c
int a = 1;
int b = 2;
int c = a + b;  // a e b vivos
int d = c + 5;  // c vivo, a e b mortos
```

Grafo de interferÃªncia:
```
a ---- c
|      |
|      |
b -----+
```

Com 2 registradores (R1, R2):
- a â†’ R1
- b â†’ R2
- c â†’ R1 (a jÃ¡ morreu)
- d â†’ R2 (b jÃ¡ morreu)

**Custo de Spilling**:
Se tivÃ©ssemos apenas 1 registrador, precisarÃ­amos fazer:
```assembly
; Sem registradores suficientes
MOV R1, 1
MOV [mem_a], R1   ; spill a
MOV R1, 2
MOV [mem_b], R1   ; spill b
MOV R1, [mem_a]   ; reload a
ADD R1, [mem_b]   ; c = a + b
; ... muito mais lento!
```

---

## MemÃ³ria e Hierarquia

### ğŸ—„ï¸ Por Que Hierarquia de MemÃ³ria?

**PrincÃ­pios**:
1. **Localidade Temporal**: Dados usados recentemente serÃ£o usados novamente em breve
2. **Localidade Espacial**: Dados prÃ³ximos a dados usados recentemente serÃ£o usados em breve

**Trade-off Fundamental**: 
- MemÃ³ria rÃ¡pida Ã© **cara e pequena**
- MemÃ³ria lenta Ã© **barata e grande**

**SoluÃ§Ã£o**: Hierarquia com mÃºltiplos nÃ­veis!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Hierarquia de MemÃ³ria                 â”‚
â”‚                                                â”‚
â”‚  Registradores  â† Mais rÃ¡pido, menor, mais caroâ”‚
â”‚       â†•         ~1 ciclo                       â”‚
â”‚    Cache L1     ~64 KB, 3-4 ciclos             â”‚
â”‚       â†•                                        â”‚
â”‚    Cache L2     ~256 KB-1 MB, 10-20 ciclos     â”‚
â”‚       â†•                                        â”‚
â”‚    Cache L3     ~8-32 MB, 40-75 ciclos         â”‚
â”‚       â†•                                        â”‚
â”‚      RAM        ~8-64 GB, 100-300 ciclos       â”‚
â”‚       â†•                                        â”‚
â”‚     SSD         ~256 GB-4 TB, milhÃµes ciclos   â”‚
â”‚       â†•                                        â”‚
â”‚     HDD         ~1-10 TB, mais milhÃµes         â”‚
â”‚                â† Mais lento, maior, mais baratoâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¾ Cache

**Como funciona**:
1. CPU precisa de dado no endereÃ§o X
2. Verifica se X estÃ¡ no cache (**cache hit**)
   - Se sim: retorna imediatamente (rÃ¡pido!)
   - Se nÃ£o (**cache miss**): busca da memÃ³ria e carrega no cache (lento)

**Tipos de Cache Miss**:
- **Compulsory miss**: Primeira vez que dado Ã© acessado
- **Capacity miss**: Cache estÃ¡ cheio
- **Conflict miss**: MÃºltiplos dados mapeiam para mesma posiÃ§Ã£o

**PolÃ­ticas de SubstituiÃ§Ã£o**:
- **LRU** (Least Recently Used): Remove o menos usado recentemente
- **LFU** (Least Frequently Used): Remove o menos frequentemente usado
- **Random**: Remove aleatoriamente

**Mapeamento de Cache**:

**Direct-Mapped**:
```
EndereÃ§o de memÃ³ria â†’ Uma Ãºnica posiÃ§Ã£o no cache
Simples, mas causa muitos conflict misses
```

**Fully Associative**:
```
EndereÃ§o de memÃ³ria â†’ Qualquer posiÃ§Ã£o no cache
FlexÃ­vel, mas hardware complexo e caro
```

**Set-Associative** (N-way):
```
Compromisso: EndereÃ§o â†’ Um conjunto com N posiÃ§Ãµes
Exemplo: 4-way set-associative Ã© comum
```

### ğŸ¯ ImplicaÃ§Ãµes para o Compilador

**OtimizaÃ§Ãµes de Cache**:

1. **Loop Tiling/Blocking**: Dividir loops grandes para caber no cache
```c
// Ruim para cache
for (i = 0; i < N; i++)
    for (j = 0; j < N; j++)
        for (k = 0; k < N; k++)
            C[i][j] += A[i][k] * B[k][j];

// Melhor para cache (blocked)
for (ii = 0; ii < N; ii += BLOCK)
    for (jj = 0; jj < N; jj += BLOCK)
        for (kk = 0; kk < N; kk += BLOCK)
            for (i = ii; i < min(ii+BLOCK, N); i++)
                for (j = jj; j < min(jj+BLOCK, N); j++)
                    for (k = kk; k < min(kk+BLOCK, N); k++)
                        C[i][j] += A[i][k] * B[k][j];
```

2. **Alinhamento de Dados**: Alinhar estruturas em mÃºltiplos da linha de cache (64 bytes tÃ­pico)

3. **Prefetching**: Compiladores podem inserir instruÃ§Ãµes de prefetch para carregar dados antecipadamente

### ğŸ“ Layout de MemÃ³ria de um Programa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” EndereÃ§os Altos (0xFFFFFFFF...)
â”‚         KERNEL          â”‚
â”‚  (EspaÃ§o do S.O.)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         STACK           â”‚ â† Cresce para baixo
â”‚  (variÃ¡veis locais,     â”‚   (SP aponta aqui)
â”‚   parÃ¢metros, endereÃ§os â”‚
â”‚   de retorno)           â”‚
â”‚           â†“             â”‚
â”‚           Â·             â”‚
â”‚           Â·             â”‚
â”‚           â†‘             â”‚
â”‚         HEAP            â”‚ â† Cresce para cima
â”‚  (malloc, new)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         BSS             â”‚
â”‚  (variÃ¡veis nÃ£o         â”‚
â”‚   inicializadas)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         DATA            â”‚
â”‚  (variÃ¡veis globais     â”‚
â”‚   inicializadas)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         TEXT            â”‚
â”‚  (cÃ³digo do programa)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ EndereÃ§os Baixos (0x00000000)
```

**Segmentos**:
- **TEXT**: CÃ³digo executÃ¡vel (read-only)
- **DATA**: VariÃ¡veis globais/estÃ¡ticas inicializadas
- **BSS**: VariÃ¡veis globais/estÃ¡ticas nÃ£o inicializadas (inicializadas com 0)
- **HEAP**: AlocaÃ§Ã£o dinÃ¢mica (malloc/free, new/delete)
- **STACK**: Chamadas de funÃ§Ã£o, variÃ¡veis locais

---

## Conjunto de InstruÃ§Ãµes (ISA)

### ğŸ® O Que Ã© ISA?

**ISA (Instruction Set Architecture)** Ã© a interface entre software e hardware. Define:
- **InstruÃ§Ãµes** disponÃ­veis
- **Tipos de dados** suportados
- **Registradores** visÃ­veis
- **Modos de endereÃ§amento**
- **Formato de instruÃ§Ãµes**

ISA Ã© o "contrato" que o processador oferece ao software.

### ğŸ“‹ Categorias de InstruÃ§Ãµes

#### 1. **InstruÃ§Ãµes AritmÃ©ticas e LÃ³gicas**

```assembly
; x86-64
ADD RAX, RBX        ; RAX = RAX + RBX
SUB RAX, 10         ; RAX = RAX - 10
MUL RCX             ; RAX = RAX * RCX (unsigned)
DIV R8              ; RAX = RAX / R8, RDX = RAX % R8

AND RAX, 0xFF       ; RAX = RAX & 0xFF (mÃ¡scara)
OR  RAX, RBX        ; RAX = RAX | RBX
XOR RAX, RAX        ; RAX = 0 (idiom comum para zerar)
NOT RAX             ; RAX = ~RAX

SHL RAX, 2          ; RAX = RAX << 2 (multiplica por 4)
SHR RAX, 1          ; RAX = RAX >> 1 (divide por 2)
```

```assembly
; MIPS
add  $t0, $t1, $t2  # $t0 = $t1 + $t2
sub  $t0, $t1, $t2  # $t0 = $t1 - $t2
addi $t0, $t1, 100  # $t0 = $t1 + 100 (imediato)
mult $t1, $t2       # Hi:Lo = $t1 * $t2
div  $t1, $t2       # Lo = $t1/$t2, Hi = $t1%$t2

and  $t0, $t1, $t2  # $t0 = $t1 & $t2
or   $t0, $t1, $t2  # $t0 = $t1 | $t2
sll  $t0, $t1, 3    # $t0 = $t1 << 3
```

#### 2. **InstruÃ§Ãµes de TransferÃªncia de Dados**

```assembly
; x86-64
MOV RAX, RBX        ; RAX = RBX
MOV RAX, [RBX]      ; RAX = memÃ³ria[RBX] (load)
MOV [RAX], RBX      ; memÃ³ria[RAX] = RBX (store)
MOV RAX, 42         ; RAX = 42 (imediato)

LEA RAX, [RBX+RCX*4+8]  ; RAX = RBX + RCX*4 + 8 (endereÃ§o)

PUSH RAX            ; [--SP] = RAX
POP RBX             ; RBX = [SP++]
```

```assembly
; MIPS
lw   $t0, 0($t1)    # $t0 = mem[$t1 + 0]
sw   $t0, 4($t1)    # mem[$t1 + 4] = $t0
lb   $t0, 0($t1)    # Load byte
sb   $t0, 0($t1)    # Store byte
lui  $t0, 0x1234    # Load upper immediate
```

#### 3. **InstruÃ§Ãµes de Controle de Fluxo**

```assembly
; x86-64
JMP label           ; PC = label (incondicional)
JE  label           ; Jump if Equal (Z=1)
JNE label           ; Jump if Not Equal (Z=0)
JL  label           ; Jump if Less (signed)
JG  label           ; Jump if Greater (signed)

CALL funÃ§Ã£o         ; PUSH PC; JMP funÃ§Ã£o
RET                 ; POP PC

CMP RAX, RBX        ; Compara (RAX - RBX), atualiza flags
TEST RAX, RAX       ; Testa (RAX & RAX), atualiza flags
```

```assembly
; MIPS
j    label          # Jump
jr   $ra            # Jump register (return)
jal  funÃ§Ã£o         # Jump and link (call)

beq  $t0, $t1, label # Branch if equal
bne  $t0, $t1, label # Branch if not equal
blt  $t0, $t1, label # Branch if less than
```

#### 4. **InstruÃ§Ãµes do Sistema**

```assembly
; x86-64
NOP                 ; No operation
HLT                 ; Halt (para o processador)
INT n               ; Software interrupt
SYSCALL             ; System call
```

### ğŸ”¢ Formato de InstruÃ§Ãµes

**Tipo R (Register)** - OperaÃ§Ãµes entre registradores:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ opcode â”‚   rs   â”‚   rt   â”‚   rd   â”‚  shamt â”‚  funct â”‚
â”‚ 6 bits â”‚ 5 bits â”‚ 5 bits â”‚ 5 bits â”‚ 5 bits â”‚ 6 bits â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Exemplo: add $t0, $t1, $t2
```

**Tipo I (Immediate)** - OperaÃ§Ãµes com valor imediato:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ opcode â”‚   rs   â”‚   rt   â”‚    immediate    â”‚
â”‚ 6 bits â”‚ 5 bits â”‚ 5 bits â”‚     16 bits     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Exemplo: addi $t0, $t1, 100
```

**Tipo J (Jump)** - Saltos:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ opcode â”‚          address             â”‚
â”‚ 6 bits â”‚          26 bits             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Exemplo: j label
```

---

## Modos de EndereÃ§amento

### ğŸ¯ Por Que Modos de EndereÃ§amento Importam?

Diferentes formas de **especificar onde os operandos estÃ£o** permitem cÃ³digo mais compacto e expressivo.

### ğŸ“ Tipos Principais

#### 1. **Imediato**
O operando Ã© uma **constante** na prÃ³pria instruÃ§Ã£o.

```assembly
MOV RAX, 42         ; RAX = 42
ADDI $t0, $t1, 100  ; $t0 = $t1 + 100
```

**Vantagem**: RÃ¡pido, nÃ£o precisa acessar memÃ³ria
**Desvantagem**: Valor limitado pelo tamanho do campo imediato

#### 2. **Registrador**
O operando estÃ¡ em um **registrador**.

```assembly
MOV RAX, RBX        ; RAX = RBX
ADD $t0, $t1, $t2   ; $t0 = $t1 + $t2
```

**Vantagem**: Muito rÃ¡pido (1 ciclo)
**Uso**: VariÃ¡veis temporÃ¡rias, acumuladores

#### 3. **Direto/Absoluto**
O endereÃ§o de memÃ³ria estÃ¡ **diretamente na instruÃ§Ã£o**.

```assembly
MOV RAX, [0x1000]   ; RAX = mem[0x1000]
LW $t0, 0x2000      ; $t0 = mem[0x2000]
```

**Vantagem**: Simples
**Uso**: VariÃ¡veis globais, endereÃ§os fixos

#### 4. **Indireto por Registrador**
O registrador **contÃ©m o endereÃ§o** do operando.

```assembly
MOV RAX, [RBX]      ; RAX = mem[RBX]
LW $t0, 0($t1)      ; $t0 = mem[$t1]
```

**Vantagem**: FlexÃ­vel, permite ponteiros
**Uso**: Ponteiros, acessos indiretos

#### 5. **Base + Deslocamento**
EndereÃ§o = Registrador base + deslocamento constante.

```assembly
MOV RAX, [RBX + 8]     ; RAX = mem[RBX + 8]
LW $t0, 12($t1)        ; $t0 = mem[$t1 + 12]
```

**Vantagem**: Acesso a campos de estruturas
**Uso**: 
```c
struct Point { int x, y; };
struct Point *p;
// p->y compilado como: MOV RAX, [RBP + 4]  (assumindo RBP aponta para p)
```

#### 6. **Indexado**
EndereÃ§o = Base + Ãndice Ã— Escala + Deslocamento.

```assembly
; x86-64: [base + index*scale + disp]
MOV RAX, [RBX + RCX*4 + 8]
; RAX = mem[RBX + RCX*4 + 8]
```

**Vantagem**: Ideal para arrays
**Uso**:
```c
int array[100];
int i = 10;
int x = array[i];  // MOV RAX, [array_base + RCX*4]
```

**Tabela comparativa**:

| Modo | Sintaxe | CÃ¡lculo do EndereÃ§o | Uso Principal |
|------|---------|---------------------|---------------|
| Imediato | `MOV RAX, 42` | N/A (constante) | Literais |
| Registrador | `MOV RAX, RBX` | N/A (registrador) | TemporÃ¡rios |
| Direto | `MOV RAX, [0x1000]` | 0x1000 | Globais |
| Indireto | `MOV RAX, [RBX]` | RBX | Ponteiros |
| Base+Desl | `MOV RAX, [RBX+8]` | RBX + 8 | Structs |
| Indexado | `MOV RAX, [RBX+RCX*4]` | RBX + RCX*4 | Arrays |

### ğŸ“ Exemplo AcadÃªmico: Compilando Acesso a Array

```c
int sum = 0;
int arr[10];
for (int i = 0; i < 10; i++) {
    sum += arr[i];
}
```

**Assembly gerado**:
```assembly
; Suponha:
; RBX = endereÃ§o base de arr
; RCX = i
; RAX = sum

    XOR RAX, RAX        ; sum = 0
    XOR RCX, RCX        ; i = 0
loop_start:
    CMP RCX, 10
    JGE loop_end
    
    ADD RAX, [RBX + RCX*4]  ; sum += arr[i]
                             ; Usa modo indexado!
    
    INC RCX             ; i++
    JMP loop_start
loop_end:
```

**Por que `RCX*4`?** Porque `int` tem 4 bytes, entÃ£o `arr[i]` estÃ¡ no endereÃ§o `base + i*sizeof(int)`.

---

## Pipeline e Paralelismo

### âš¡ Pipeline de InstruÃ§Ãµes

**Conceito**: Dividir execuÃ§Ã£o de instruÃ§Ãµes em **estÃ¡gios**, permitindo **mÃºltiplas instruÃ§Ãµes** em diferentes estÃ¡gios **simultaneamente**.

**Analogia**: Linha de montagem de carros.
- EstaÃ§Ã£o 1: Monta chassi
- EstaÃ§Ã£o 2: Instala motor
- EstaÃ§Ã£o 3: Pinta
- EstaÃ§Ã£o 4: Acabamento

Sem pipeline: 1 carro a cada 4 horas
Com pipeline: 1 carro a cada 1 hora (apÃ³s o primeiro)

**Pipeline ClÃ¡ssico de 5 EstÃ¡gios (RISC)**:

```
EstÃ¡gio 1: IF  (Instruction Fetch)    - Busca instruÃ§Ã£o
EstÃ¡gio 2: ID  (Instruction Decode)   - Decodifica, lÃª registradores
EstÃ¡gio 3: EX  (Execute)              - Executa na ALU
EstÃ¡gio 4: MEM (Memory Access)        - Acessa memÃ³ria (load/store)
EstÃ¡gio 5: WB  (Write Back)           - Escreve resultado
```

**Exemplo de ExecuÃ§Ã£o**:

```
Ciclo: 1    2    3    4    5    6    7    8    9
I1:   IF   ID   EX  MEM   WB
I2:        IF   ID   EX  MEM   WB
I3:             IF   ID   EX  MEM   WB
I4:                  IF   ID   EX  MEM   WB
I5:                       IF   ID   EX  MEM   WB
```

**Sem pipeline**: 5 instruÃ§Ãµes Ã— 5 ciclos = 25 ciclos
**Com pipeline**: 5 + 4 = 9 ciclos (speedup de ~2.78x)

**Speedup ideal**: N estÃ¡gios â†’ speedup de Nx (assintoticamente)

### ğŸš§ Hazards (Perigos) de Pipeline

#### 1. **Hazards Estruturais**
Dois estÃ¡gios precisam do mesmo recurso ao mesmo tempo.

**Exemplo**: Se IF e MEM usam a mesma memÃ³ria:
```
I1: IF   ID   EX  MEM   WB
I2:      IF  (conflito! I1 estÃ¡ acessando memÃ³ria)
```

**SoluÃ§Ã£o**: Cache separado para instruÃ§Ãµes e dados (arquitetura Harvard)

#### 2. **Hazards de Dados**
InstruÃ§Ã£o depende de resultado de instruÃ§Ã£o anterior ainda nÃ£o concluÃ­da.

**Exemplo**:
```assembly
ADD R1, R2, R3    ; R1 = R2 + R3
SUB R4, R1, R5    ; R4 = R1 - R5  (precisa de R1!)
```

```
ADD: IF   ID   EX  MEM   WB
SUB:      IF   ID  (precisa de R1, mas ADD ainda nÃ£o escreveu!)
```

**SoluÃ§Ãµes**:
- **Stalling**: Parar pipeline atÃ© resultado estar pronto (insere "bolhas")
- **Forwarding/Bypassing**: Passar resultado diretamente de EX para prÃ³xima instruÃ§Ã£o
- **ReordenaÃ§Ã£o por compilador**: Reorganizar instruÃ§Ãµes independentes

**Compilador pode ajudar**:
```assembly
; CÃ³digo original (hazard)
ADD R1, R2, R3
SUB R4, R1, R5

; Reordenado pelo compilador (sem hazard)
ADD R1, R2, R3
MUL R6, R7, R8    ; InstruÃ§Ã£o independente
SUB R4, R1, R5
```

#### 3. **Hazards de Controle (Branch Hazards)**
NÃ£o sabemos qual instruÃ§Ã£o buscar apÃ³s um branch atÃ© ele ser resolvido.

```assembly
BEQ R1, R2, label
ADD R3, R4, R5       ; Buscar esta?
...
label: SUB R6, R7, R8 ; Ou esta?
```

**SoluÃ§Ãµes**:
- **Stalling**: Esperar resoluÃ§Ã£o (ineficiente)
- **Branch Prediction**: Prever resultado do branch
  - **EstÃ¡tico**: Sempre prevÃª "nÃ£o tomado" ou sempre "tomado"
  - **DinÃ¢mico**: Usa histÃ³rico (tabelas BTB, PHT)
- **Speculative Execution**: Executa instruÃ§Ãµes especulativamente, descarta se errado

**Impacto no Compilador**:
- **Branch Delay Slot** (MIPS): Compilador deve preencher slot apÃ³s branch com instruÃ§Ã£o Ãºtil
```assembly
BEQ R1, R2, label
ADD R3, R4, R5       ; Sempre executada (delay slot)
```

### ğŸ”€ Paralelismo em NÃ­vel de InstruÃ§Ã£o (ILP)

**Superscalar**: MÃºltiplas instruÃ§Ãµes por ciclo (mÃºltiplos pipelines).

**Exemplo**: Processador 4-way superscalar pode executar 4 instruÃ§Ãµes simultÃ¢neas:
```
Ciclo 1: I1, I2, I3, I4 (todos em IF)
Ciclo 2: I5, I6, I7, I8 (IF); I1, I2, I3, I4 (ID)
...
```

**VLIW (Very Long Instruction Word)**:
Compilador agrupa instruÃ§Ãµes paralelas:
```
[ADD R1,R2,R3 | MUL R4,R5,R6 | LOAD R7,0(R8) | STORE R9,0(R10)]
```

**SIMD (Single Instruction, Multiple Data)**:
Uma instruÃ§Ã£o opera em mÃºltiplos dados:
```assembly
; SSE: Soma 4 floats de uma vez
ADDPS XMM0, XMM1   ; XMM0[0-3] += XMM1[0-3]
```

---

## ConvenÃ§Ãµes de Chamada de FunÃ§Ã£o

### ğŸ“ Calling Conventions

Define **como** funÃ§Ãµes sÃ£o chamadas:
- Como **argumentos** sÃ£o passados?
- Como **valor de retorno** Ã© passado?
- Quais **registradores** devem ser preservados?
- Quem **limpa a pilha**?

### ğŸ¯ x86-64 System V ABI (Linux, macOS)

**Passagem de Argumentos** (inteiros/ponteiros):
1. RDI - primeiro argumento
2. RSI - segundo
3. RDX - terceiro
4. RCX - quarto
5. R8  - quinto
6. R9  - sexto
7+ - Pilha (direita para esquerda)

**Retorno**:
- RAX - valor de retorno

**Registradores Preservados (callee-saved)**:
```
RBX, RBP, R12-R15
FunÃ§Ã£o deve salvar/restaurar se usar
```

**Registradores NÃ£o-Preservados (caller-saved)**:
```
RAX, RCX, RDX, RSI, RDI, R8-R11
Chamador deve salvar se precisar manter
```

**Exemplo**:
```c
int foo(int a, int b, int c) {
    return a + b + c;
}

int main() {
    int result = foo(1, 2, 3);
    return 0;
}
```

```assembly
foo:
    ; a em EDI, b em ESI, c em EDX
    MOV EAX, EDI        ; EAX = a
    ADD EAX, ESI        ; EAX += b
    ADD EAX, EDX        ; EAX += c
    RET                 ; retorna EAX

main:
    ; Preparar chamada
    MOV EDI, 1          ; primeiro arg
    MOV ESI, 2          ; segundo arg
    MOV EDX, 3          ; terceiro arg
    CALL foo
    ; Resultado em EAX
    RET
```

### ğŸ—ï¸ Stack Frame

Cada chamada de funÃ§Ã£o cria um **frame** na pilha:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† RSP (topo da pilha) 
â”‚  VariÃ¡veis Locais   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Registradores      â”‚
â”‚  Salvos             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â† RBP (base do frame)
â”‚  RBP Anterior       â”‚  (saved frame pointer)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EndereÃ§o Retorno   â”‚  (return address)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Argumentos 7+      â”‚  (se houver)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     ...             â”‚
â”‚  Frame da FunÃ§Ã£o    â”‚
â”‚  Chamadora          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PrÃ³logo da FunÃ§Ã£o** (setup do frame):
```assembly
PUSH RBP            ; Salva frame pointer anterior
MOV RBP, RSP        ; RBP = novo frame base
SUB RSP, N          ; Aloca N bytes para variÃ¡veis locais
```

**EpÃ­logo da FunÃ§Ã£o** (teardown):
```assembly
MOV RSP, RBP        ; Restaura SP
POP RBP             ; Restaura frame pointer
RET                 ; Retorna
```

Ou de forma otimizada:
```assembly
LEAVE               ; Equivalente a MOV RSP,RBP; POP RBP
RET
```

### ğŸ“ Exemplo Completo

```c
int soma_e_multiplica(int x, int y) {
    int temp = x + y;
    return temp * 2;
}
```

```assembly
soma_e_multiplica:
    PUSH RBP                ; Salva frame pointer
    MOV RBP, RSP            ; Setup novo frame
    SUB RSP, 16             ; Aloca espaÃ§o (16-byte aligned)
    
    ; x em EDI, y em ESI
    MOV EAX, EDI            ; EAX = x
    ADD EAX, ESI            ; EAX = x + y
    MOV [RBP-4], EAX        ; temp = x + y (variÃ¡vel local)
    
    MOV EAX, [RBP-4]        ; EAX = temp
    ADD EAX, EAX            ; EAX = temp * 2
    
    LEAVE                   ; Cleanup frame
    RET                     ; Retorna EAX
```

---

## CompilaÃ§Ã£o e GeraÃ§Ã£o de CÃ³digo

### ğŸ”„ Do CÃ³digo Fonte ao Assembly

**Pipeline de CompilaÃ§Ã£o**:
```
CÃ³digo Fonte (.c)
      â†“
Preprocessador (cpp)
      â†“
CÃ³digo C Expandido
      â†“
Compilador (gcc -S)
      â†“
Assembly (.s)
      â†“
Assembler (as)
      â†“
CÃ³digo Objeto (.o)
      â†“
Linker (ld)
      â†“
ExecutÃ¡vel
```

### ğŸ¯ Exemplo: ExpressÃµes AritmÃ©ticas

```c
int x = (a + b) * (c - d);
```

**AST (Abstract Syntax Tree)**:
```
        =
       / \
      x   *
         / \
        +   -
       / \ / \
      a  b c  d
```

**CÃ³digo de TrÃªs EndereÃ§os** (IR):
```
t1 = a + b
t2 = c - d
t3 = t1 * t2
x = t3
```

**Assembly (x86-64)**:
```assembly
; Assumindo: a em [RBP-4], b em [RBP-8], c em [RBP-12], d em [RBP-16]
MOV EAX, [RBP-4]        ; EAX = a
ADD EAX, [RBP-8]        ; EAX = a + b
MOV EBX, [RBP-12]       ; EBX = c
SUB EBX, [RBP-16]       ; EBX = c - d
IMUL EAX, EBX           ; EAX = (a+b) * (c-d)
MOV [RBP-20], EAX       ; x = resultado
```

**Com OtimizaÃ§Ã£o** (se a, b, c, d em registradores):
```assembly
; a=EDI, b=ESI, c=EDX, d=ECX
ADD EDI, ESI            ; EDI = a + b
SUB EDX, ECX            ; EDX = c - d
IMUL EDI, EDX           ; EDI = (a+b)*(c-d)
; Resultado em EDI
```

### ğŸ“ Exemplo: Estruturas de Controle

#### IF-ELSE

```c
if (x > 10) {
    y = 1;
} else {
    y = 2;
}
```

```assembly
    CMP DWORD PTR [x], 10   ; Compara x com 10
    JLE else_label          ; Se x <= 10, vai para else
then_label:
    MOV DWORD PTR [y], 1    ; y = 1
    JMP endif_label
else_label:
    MOV DWORD PTR [y], 2    ; y = 2
endif_label:
    ; Continua...
```

#### WHILE Loop

```c
int i = 0;
while (i < 10) {
    sum += i;
    i++;
}
```

```assembly
    MOV DWORD PTR [i], 0        ; i = 0
loop_start:
    CMP DWORD PTR [i], 10       ; i < 10?
    JGE loop_end                ; Se nÃ£o, sai do loop
    
    MOV EAX, [i]
    ADD [sum], EAX              ; sum += i
    INC DWORD PTR [i]           ; i++
    
    JMP loop_start
loop_end:
```

#### FOR Loop

```c
for (int i = 0; i < 10; i++) {
    arr[i] = i * 2;
}
```

```assembly
    XOR ECX, ECX                ; i = 0 (ECX usado como contador)
for_start:
    CMP ECX, 10
    JGE for_end
    
    MOV EAX, ECX                ; EAX = i
    SHL EAX, 1                  ; EAX = i * 2
    LEA RDX, [arr]              ; RDX = endereÃ§o base de arr
    MOV [RDX + RCX*4], EAX      ; arr[i] = i * 2
    
    INC ECX
    JMP for_start
for_end:
```

---

## Arquiteturas RISC vs CISC

### ğŸ›ï¸ CISC (Complex Instruction Set Computer)

**Filosofia**: InstruÃ§Ãµes complexas que fazem muito em uma instruÃ§Ã£o.

**CaracterÃ­sticas**:
- **InstruÃ§Ãµes variÃ¡veis**: 1-15 bytes (x86)
- **Muitas instruÃ§Ãµes**: Centenas de instruÃ§Ãµes diferentes
- **EndereÃ§amento complexo**: MÃºltiplos modos
- **Poucos registradores**: Historicamente (x86 tinha 8)
- **MicrocÃ³digo**: InstruÃ§Ãµes complexas decompostas internamente

**Exemplo x86**:
```assembly
; Uma instruÃ§Ã£o pode fazer muito
MOVS    ; Move string (copia bloco de memÃ³ria)
LOOP    ; Decrementa contador e branch
REP MOVSB  ; Repete MOVSB atÃ© contador zerar
```

**Vantagens**:
- CÃ³digo mais compacto
- Menos instruÃ§Ãµes para mesma tarefa
- Ãštil quando memÃ³ria Ã© cara/lenta

**Desvantagens**:
- InstruÃ§Ãµes lentas (mÃºltiplos ciclos)
- DifÃ­cil pipeline
- Hardware complexo

### âš¡ RISC (Reduced Instruction Set Computer)

**Filosofia**: InstruÃ§Ãµes simples, rÃ¡pidas, executÃ¡veis em poucos ciclos.

**CaracterÃ­sticas**:
- **InstruÃ§Ãµes fixas**: 32 bits (MIPS, ARM)
- **Poucas instruÃ§Ãµes**: ~100-200 instruÃ§Ãµes
- **EndereÃ§amento simples**: Poucos modos
- **Muitos registradores**: 32 registradores (MIPS)
- **Load/Store**: SÃ³ LOAD e STORE acessam memÃ³ria

**Exemplo MIPS**:
```assembly
LW  $t0, 0($t1)     ; Load
ADD $t0, $t0, $t2   ; Compute
SW  $t0, 0($t1)     ; Store
```

**Vantagens**:
- InstruÃ§Ãµes rÃ¡pidas (1 ciclo ideal)
- Pipeline eficiente
- Hardware simples

**Desvantagens**:
- Mais instruÃ§Ãµes para mesma tarefa
- CÃ³digo maior

### ğŸ“Š ComparaÃ§Ã£o

| Aspecto | CISC (x86) | RISC (MIPS, ARM) |
|---------|------------|------------------|
| **Tamanho InstruÃ§Ã£o** | VariÃ¡vel | Fixo |
| **Complexidade** | Alta | Baixa |
| **Registradores** | Poucos | Muitos |
| **Modos EndereÃ§amento** | Muitos | Poucos |
| **Pipeline** | DifÃ­cil | FÃ¡cil |
| **Exemplo** | Intel x86, AMD64 | MIPS, ARM, RISC-V |

### ğŸ”„ ConvergÃªncia Moderna

Processadores modernos **convergem**:
- **x86 moderno**: Internamente RISC (micro-ops), externamente CISC
- **ARM moderno**: Adiciona instruÃ§Ãµes complexas (Thumb)

Intel/AMD decompÃµem instruÃ§Ãµes x86 complexas em **micro-operaÃ§Ãµes** RISC-like que sÃ£o executadas por pipeline RISC.

---

## Exemplos PrÃ¡ticos

### ğŸ’» Exemplo 1: Soma Simples em Inline Assembly

Ver arquivo `exemploSomaSimplesAssmbly.c` neste diretÃ³rio.

### ğŸ’» Exemplo 2: FunÃ§Ã£o Recursiva (Fatorial)

```c
int fatorial(int n) {
    if (n <= 1) return 1;
    return n * fatorial(n - 1);
}
```

**Assembly**:
```assembly
fatorial:
    PUSH RBP
    MOV RBP, RSP
    
    ; n em EDI
    CMP EDI, 1
    JG recursivo
    
    ; Caso base: n <= 1
    MOV EAX, 1
    POP RBP
    RET
    
recursivo:
    PUSH RDI                ; Salva n
    DEC EDI                 ; n - 1
    CALL fatorial           ; Chamada recursiva
    POP RDI                 ; Restaura n
    IMUL EAX, EDI           ; n * fatorial(n-1)
    
    POP RBP
    RET
```

### ğŸ’» Exemplo 3: Acesso a Estrutura

```c
struct Point {
    int x;
    int y;
};

int soma_coordenadas(struct Point *p) {
    return p->x + p->y;
}
```

**Assembly**:
```assembly
soma_coordenadas:
    ; p em RDI (ponteiro para struct)
    MOV EAX, [RDI]          ; EAX = p->x (offset 0)
    ADD EAX, [RDI + 4]      ; EAX += p->y (offset 4)
    RET
```

**ExplicaÃ§Ã£o dos Offsets**:
```
struct Point em memÃ³ria:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  x (4B)  â”‚  y (4B)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
offset: 0      4
```

---

## ExercÃ­cios AcadÃªmicos

### ğŸ“ ExercÃ­cio 1: AnÃ¡lise de CÃ³digo Assembly

Dado o cÃ³digo assembly abaixo, determine o que ele faz:

```assembly
mystery:
    XOR EAX, EAX        ; EAX = 0
    XOR ECX, ECX        ; ECX = 0
loop_start:
    CMP ECX, EDI
    JGE loop_end
    ADD EAX, ECX
    INC ECX
    JMP loop_start
loop_end:
    RET
```

**Resposta**: Calcula a soma de 0 atÃ© n-1 (n em EDI). Equivalente a:
```c
int mystery(int n) {
    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += i;
    }
    return sum;
}
```

### ğŸ“ ExercÃ­cio 2: OtimizaÃ§Ã£o

Compare as duas versÃµes abaixo. Qual Ã© mais eficiente e por quÃª?

**VersÃ£o A**:
```assembly
MOV EAX, [x]
IMUL EAX, 8
```

**VersÃ£o B**:
```assembly
MOV EAX, [x]
SHL EAX, 3
```

**Resposta**: VersÃ£o B Ã© mais eficiente. `SHL` (shift left) Ã© mais rÃ¡pido que `IMUL` (multiplicaÃ§Ã£o). Multiplicar por 8 = deslocar 3 bits Ã  esquerda (8 = 2Â³). Compiladores fazem essa otimizaÃ§Ã£o automaticamente (**strength reduction**).

### ğŸ“ ExercÃ­cio 3: GeraÃ§Ã£o de CÃ³digo

Compile a seguinte expressÃ£o para assembly x86-64:

```c
int resultado = (a * b) + (c / d);
```

Assuma que a, b, c, d estÃ£o em EDI, ESI, EDX, ECX respectivamente.

**Resposta**:
```assembly
IMUL EDI, ESI       ; EDI = a * b
MOV EAX, EDX        ; EAX = c
CDQ                 ; Estende sinal de EAX para EDX:EAX
IDIV ECX            ; EAX = c / d
ADD EAX, EDI        ; EAX = (a*b) + (c/d)
; Resultado em EAX
```

### ğŸ“ ExercÃ­cio 4: Stack Frames

Desenhe o stack frame para a seguinte chamada:

```c
int foo(int a, int b) {
    int x = a + b;
    int y = x * 2;
    return y;
}

int main() {
    int z = foo(3, 5);
}
```

**Resposta**:
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† RSP ao entrar em foo
        â”‚  (alinhamento)  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  y (4 bytes)    â”‚ RBP - 8
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  x (4 bytes)    â”‚ RBP - 4
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â† RBP
        â”‚  RBP salvo      â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ return address  â”‚ (onde retornar em main)
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  ...            â”‚
        â”‚  Frame de main  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ ExercÃ­cio 5: Contagem de Ciclos

Dado um pipeline de 5 estÃ¡gios, quantos ciclos sÃ£o necessÃ¡rios para executar 10 instruÃ§Ãµes **sem hazards**?

**Resposta**: 
- Primeira instruÃ§Ã£o: 5 ciclos
- PrÃ³ximas 9 instruÃ§Ãµes: 1 ciclo cada = 9 ciclos
- **Total: 14 ciclos**

Sem pipeline: 10 Ã— 5 = 50 ciclos
Speedup: 50/14 â‰ˆ 3.57x

---

## Perguntas para Pensar

### ğŸ¤” Pergunta 1: Por que registradores sÃ£o tÃ£o rÃ¡pidos?

**Pergunta**: Por que acessar um registrador leva 1 ciclo, mas acessar RAM leva 100+ ciclos?

**Resposta**: 

MÃºltiplos fatores:

1. **Proximidade fÃ­sica**: Registradores estÃ£o **dentro da CPU**, a poucos micrÃ´metros dos circuitos de execuÃ§Ã£o. RAM estÃ¡ em chips separados, centÃ­metros de distÃ¢ncia.

2. **Tecnologia**: Registradores usam **flip-flops** (6-8 transistores por bit), extremamente rÃ¡pidos mas caros. RAM usa **capacitores** (1 transistor + 1 capacitor por bit), mais lentos mas muito mais densos.

3. **Paralelismo**: Todos os bits de um registrador sÃ£o acessados simultaneamente (64 bits em paralelo). MemÃ³ria tem barramento limitado.

4. **LatÃªncia elÃ©trica**: Sinais elÃ©tricos levam tempo para viajar. Mesmo Ã  velocidade da luz no silÃ­cio (~c/3), distÃ¢ncia importa.

5. **Complexidade do controlador**: Acessar RAM requer:
   - Enviar endereÃ§o pelo barramento
   - Esperar DRAM refresh se necessÃ¡rio
   - Esperar CAS/RAS latency
   - Receber dados de volta

**Analogia**: Registrador = nota no seu bolso (acesso instantÃ¢neo). RAM = item em uma gaveta (precisa abrir, procurar, pegar).

### ğŸ¤” Pergunta 2: Por que nÃ£o fazer tudo em registradores?

**Pergunta**: Se registradores sÃ£o tÃ£o rÃ¡pidos, por que nÃ£o ter milhares deles em vez de RAM?

**Resposta**:

1. **Custo**: Registradores sÃ£o **extremamente caros**. Um chip com 1000 registradores de 64 bits custaria mais que todo o resto do processador combinado.

2. **EspaÃ§o fÃ­sico**: Flip-flops ocupam muito espaÃ§o no die. Ãrea Ã© preciosa â€” cada mmÂ² poderia ter mais cache ou mais nÃºcleos.

3. **Energia**: Registradores consomem **muita energia** porque sÃ£o sempre ativos. Milhares deles tornariam o processador forno.

4. **Complexidade de roteamento**: Mais registradores = mais fios interconectando = mais complexidade = maior latÃªncia nas conexÃµes.

5. **Retornos decrescentes**: Para muitas aplicaÃ§Ãµes, 16-32 registradores sÃ£o suficientes com boa alocaÃ§Ã£o.

**PrincÃ­pio econÃ´mico**: Hierarquia de memÃ³ria reflete **trade-offs Ã³timos** entre velocidade, custo, e capacidade.

### ğŸ¤” Pergunta 3: Como branch prediction funciona?

**Pergunta**: Como o processador "adivinha" o resultado de um `if` antes de executÃ¡-lo?

**Resposta**:

**Branch Predictors** usam **histÃ³rico** para prever branches:

**1-bit Predictor**:
- Se Ãºltimo branch foi tomado â†’ prevÃª tomado
- Se nÃ£o tomado â†’ prevÃª nÃ£o tomado

**Problema**: Loops alternam previsÃ£o no final!
```c
for (i = 0; i < 100; i++) { ... }
// 99x tomado, 1x nÃ£o tomado
// 1-bit erra 2x por loop (fim e recomeÃ§o)
```

**2-bit Predictor** (Saturating Counter):
```
Estados:
00: Fortemente NÃ£o-Tomado
01: Fracamente NÃ£o-Tomado
10: Fracamente Tomado
11: Fortemente Tomado

TransiÃ§Ãµes:
Tomado: incrementa (satura em 11)
NÃ£o-Tomado: decrementa (satura em 00)
```

Agora loops funcionam bem: precisa 2 erros consecutivos para mudar previsÃ£o.

**Branch Target Buffer (BTB)**:
Cache que armazena:
- PC do branch
- EndereÃ§o alvo
- HistÃ³rico (2-bit counter)

**Two-Level Adaptive Predictor**:
Usa **padrÃµes de histÃ³rico**:
```
00101 â†’ Tomado
00110 â†’ NÃ£o-Tomado
```

Aprende **correlaÃ§Ãµes** entre branches.

**Modern Predictors**:
- **Perceptron-based**: Usa redes neurais simples
- **TAGE**: Tagged Geometric History Length
- **Accuracy**: >95% em cÃ³digo real!

**Custo de Missprediction**:
- Pipeline precisa ser **flushed**
- ~15-20 ciclos de penalidade
- Por isso alta taxa de acerto Ã© crÃ­tica

### ğŸ¤” Pergunta 4: Por que x86 domina desktops mas ARM domina mobile?

**Pergunta**: Por que arquiteturas diferentes dominam mercados diferentes?

**Resposta**:

**x86 em Desktops/Servers**:

**Vantagens**:
1. **Legacy**: DÃ©cadas de software compilado para x86
2. **Compatibilidade**: Rodar software antigo sem recompilaÃ§Ã£o
3. **Performance absoluta**: CISC permite performance alta com muito poder/espaÃ§o
4. **Ecossistema**: Ferramentas, drivers, otimizaÃ§Ãµes maduras

**Desvantagens**:
1. **Consumo de energia**: CISC complexo gasta mais energia
2. **Custo**: Chips mais complexos, mais caros
3. **Tamanho**: Dies maiores

**ARM em Mobile/Embedded**:

**Vantagens**:
1. **EficiÃªncia energÃ©tica**: RISC simples â†’ menos energia por instruÃ§Ã£o
2. **Custo**: Menor Ã¡rea de silÃ­cio â†’ mais barato
3. **Calor**: Menos dissipaÃ§Ã£o tÃ©rmica (crucial em dispositivos passivamente resfriados)
4. **Licenciamento**: ARM licencia designs, permitindo customizaÃ§Ã£o

**Desvantagens**:
1. **Performance absoluta**: Historicamente menor (mudando com Apple M1/M2!)
2. **Ecossistema**: Menos software nativo (mas melhorando)

**ConvergÃªncia**:
- ARM invade data centers (AWS Graviton)
- Apple M1/M2 provam que ARM pode competir em desktops
- x86 melhora eficiÃªncia energÃ©tica
- DiferenÃ§as diminuindo com designs hÃ­bridos

**Resposta curta**: **Requisitos diferentes**. Desktop prioriza performance e compatibilidade. Mobile prioriza bateria e custo.

### ğŸ¤” Pergunta 5: O que Ã© o "Gargalo de von Neumann"?

**Pergunta**: Qual Ã© a limitaÃ§Ã£o fundamental da arquitetura de von Neumann?

**Resposta**:

**Gargalo de von Neumann**: O **barramento compartilhado** entre CPU e memÃ³ria limita throughput.

**Problema**:
```
CPU (rÃ¡pida, GHz) â†â†’ Barramento (lento) â†â†’ MemÃ³ria (lenta)
```

- CPU pode executar bilhÃµes de instruÃ§Ãµes por segundo
- Mas sÃ³ pode buscar ~milhÃµes de dados por segundo da RAM
- **CPU fica esperando memÃ³ria** (memory-bound programs)

**ConsequÃªncias**:
1. **Cache essencial**: Sem cache, CPUs modernas seriam ~100x mais lentas
2. **Prefetching**: Buscar dados antecipadamente
3. **Bandwidth vs. Latency**: Ambos limitados

**SoluÃ§Ãµes**:

**1. Hierarquia de MemÃ³ria**:
- MÃºltiplos nÃ­veis de cache amenizam problema

**2. Arquitetura Harvard**:
- Barramentos separados para instruÃ§Ãµes e dados
- Usado em DSPs, microcontroladores

**3. MemÃ³ria On-Die**:
- eDRAM, HBM (High Bandwidth Memory)
- MemÃ³ria mais prÃ³xima da CPU

**4. Processamento In-Memory**:
- Executar computaÃ§Ã£o na prÃ³pria memÃ³ria
- Elimina transferÃªncias

**5. Paralelismo**:
- MÃºltiplos cores acessam memÃ³ria simultaneamente
- NUMA (Non-Uniform Memory Access)

**Impacto no Design de Algoritmos**:
Algoritmos devem ser **cache-friendly**:
- Localidade espacial e temporal
- Blocking/tiling de loops
- Estruturas de dados compactas

**Analogia**: Cozinheiro muito rÃ¡pido (CPU) com geladeira pequena (cache) e supermercado longe (RAM). Maior parte do tempo Ã© gasto indo e voltando do supermercado, nÃ£o cozinhando!

### ğŸ¤” Pergunta 6: Como compiladores otimizam loops?

**Pergunta**: Que transformaÃ§Ãµes compiladores aplicam para acelerar loops?

**Resposta**:

**1. Loop Invariant Code Motion (LICM)**:
Move cÃ¡lculos que nÃ£o mudam para fora do loop.

```c
// Antes
for (i = 0; i < n; i++) {
    x = y + z;  // y e z nÃ£o mudam!
    a[i] = x * i;
}

// Depois
x = y + z;
for (i = 0; i < n; i++) {
    a[i] = x * i;
}
```

**2. Loop Unrolling**:
Desenrola loop para reduzir overhead de controle e permitir mais ILP.

```c
// Antes
for (i = 0; i < 100; i++) {
    sum += a[i];
}

// Depois (unroll 4x)
for (i = 0; i < 100; i += 4) {
    sum += a[i];
    sum += a[i+1];
    sum += a[i+2];
    sum += a[i+3];
}
```

**BenefÃ­cios**:
- Menos branches
- Mais instruÃ§Ãµes independentes (melhor ILP)
- Melhor uso de pipeline

**3. Loop Fusion**:
Combina loops adjacentes que iteram sobre mesmos dados.

```c
// Antes
for (i = 0; i < n; i++) a[i] = b[i] + 1;
for (i = 0; i < n; i++) c[i] = a[i] * 2;

// Depois
for (i = 0; i < n; i++) {
    a[i] = b[i] + 1;
    c[i] = a[i] * 2;
}
```

**BenefÃ­cio**: Melhor localidade de cache.

**4. Loop Tiling/Blocking**:
Divide loop para caber dados no cache.

```c
// MultiplicaÃ§Ã£o de matrizes
// Antes: percorre matrizes grandes
for (i = 0; i < N; i++)
    for (j = 0; j < N; j++)
        for (k = 0; k < N; k++)
            C[i][j] += A[i][k] * B[k][j];

// Depois: processa blocos que cabem no cache
for (ii = 0; ii < N; ii += TILE)
    for (jj = 0; jj < N; jj += TILE)
        for (kk = 0; kk < N; kk += TILE)
            for (i = ii; i < min(ii+TILE,N); i++)
                for (j = jj; j < min(jj+TILE,N); j++)
                    for (k = kk; k < min(kk+TILE,N); k++)
                        C[i][j] += A[i][k] * B[k][j];
```

**5. VetorizaÃ§Ã£o (SIMD)**:
Transforma loop em operaÃ§Ãµes vetoriais.

```c
// Antes
for (i = 0; i < n; i++) {
    c[i] = a[i] + b[i];
}

// Assembly vetorizado (AVX)
for (i = 0; i < n; i += 8) {
    __m256 va = _mm256_load_ps(&a[i]);
    __m256 vb = _mm256_load_ps(&b[i]);
    __m256 vc = _mm256_add_ps(va, vb);
    _mm256_store_ps(&c[i], vc);
}
// 8 adiÃ§Ãµes em uma instruÃ§Ã£o!
```

**6. Software Pipelining**:
Solapa iteraÃ§Ãµes para manter pipeline cheio.

**7. Loop Strength Reduction**:
Substitui operaÃ§Ãµes caras por baratas.

```c
// Antes
for (i = 0; i < n; i++) {
    a[i] = i * 5;  // MultiplicaÃ§Ã£o
}

// Depois
for (i = 0, t = 0; i < n; i++, t += 5) {
    a[i] = t;  // AdiÃ§Ã£o
}
```

---

## ReferÃªncias e Leitura Adicional

### ğŸ“š Livros Fundamentais

1. **Patterson, D. A., & Hennessy, J. L.** (2017). *Computer Organization and Design: The Hardware/Software Interface* (5th ed.). Morgan Kaufmann.
   - O livro definitivo sobre organizaÃ§Ã£o de computadores
   - Abordagem MIPS/RISC
   - Excelente para entender pipeline, cache, paralelismo

2. **Hennessy, J. L., & Patterson, D. A.** (2017). *Computer Architecture: A Quantitative Approach* (6th ed.). Morgan Kaufmann.
   - Mais avanÃ§ado que o anterior
   - Foco em performance e mÃ©tricas quantitativas
   - Essencial para otimizaÃ§Ãµes de compiladores

3. **Tanenbaum, A. S., & Austin, T.** (2012). *Structured Computer Organization* (6th ed.). Pearson.
   - Abordagem em camadas: digital logic â†’ microarchitecture â†’ ISA â†’ OS
   - Excelente para entender abstraÃ§Ã£o

4. **Bryant, R. E., & O'Hallaron, D. R.** (2015). *Computer Systems: A Programmer's Perspective* (3rd ed.). Pearson.
   - Perspectiva do programador
   - Excelente cobertura de assembly x86-64, otimizaÃ§Ãµes, memÃ³ria

5. **Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D.** (2006). *Compilers: Principles, Techniques, and Tools* (2nd ed.). Pearson.
   - O "Livro do DragÃ£o"
   - Conecta compiladores com arquitetura
   - GeraÃ§Ã£o e otimizaÃ§Ã£o de cÃ³digo

### ğŸŒ Recursos Online

**DocumentaÃ§Ã£o Oficial**:
- **IntelÂ® 64 and IA-32 Architectures Software Developer Manuals**: https://www.intel.com/sdm
- **ARM Architecture Reference Manual**: https://developer.arm.com/documentation
- **RISC-V Specifications**: https://riscv.org/technical/specifications/

**Cursos**:
- **Nand2Tetris**: https://www.nand2tetris.org/ (construa um computador do zero!)
- **MIT 6.004**: Computation Structures (https://6004.mit.edu/)
- **CS:APP (Bryant & O'Hallaron)**: http://csapp.cs.cmu.edu/

**Ferramentas Interativas**:
- **Compiler Explorer**: https://godbolt.org/ (veja assembly gerado por compiladores)
- **CPU Simulator**: https://github.com/mortbopet/Ripes (simula RISC-V)

### ğŸ”§ Ferramentas PrÃ¡ticas

**Disassemblers/Debuggers**:
```bash
# Disassembly de binÃ¡rio
objdump -d executavel

# GDB para debug
gdb executavel

# Veja cÃ³digo assembly gerado
gcc -S -O2 programa.c

# Veja otimizaÃ§Ãµes aplicadas
gcc -O2 -fopt-info-vec programa.c
```

**Performance Analysis**:
```bash
# Conta ciclos, cache misses, etc
perf stat ./programa

# Profiling
perf record ./programa
perf report

# Cache analysis
valgrind --tool=cachegrind ./programa
```

### ğŸ“Š Papers ClÃ¡ssicos

1. **Hennessy, J., & Patterson, D.** (2012). "Computer Architecture: A Quantitative Approach"
   - Define mÃ©tricas de performance fundamentais

2. **Yeh, T. Y., & Patt, Y. N.** (1991). "Two-Level Adaptive Training Branch Prediction"
   - Branch prediction moderno

3. **Lam, M. S., Rothberg, E. E., & Wolf, M. E.** (1991). "The Cache Performance and Optimizations of Blocked Algorithms"
   - Loop tiling para otimizaÃ§Ã£o de cache

---

## ğŸ“ ConclusÃ£o

OrganizaÃ§Ã£o de computadores Ã© **fundamental** para qualquer engenheiro de compiladores. Entender como o hardware funciona permite:

1. **Gerar cÃ³digo eficiente**: Explorar registradores, cache, pipeline
2. **Fazer trade-offs informados**: Tamanho vs. velocidade, memÃ³ria vs. computaÃ§Ã£o
3. **Depurar efetivamente**: Entender assembly facilita debugging de baixo nÃ­vel
4. **Otimizar algoritmos**: Algoritmos cache-aware sÃ£o ordens de magnitude mais rÃ¡pidos

**PrÃ³ximos Passos**:
- Implemente os exercÃ­cios propostos
- Explore cÃ³digos gerados por compiladores reais (gcc, clang)
- Estude otimizaÃ§Ãµes especÃ­ficas para arquitetura alvo
- Experimente com inline assembly
- Leia especificaÃ§Ãµes de ISAs reais

**Lembre-se**: A fronteira entre hardware e software Ã© onde a mÃ¡gica acontece. Compiladores sÃ£o a ponte que torna computaÃ§Ã£o abstrata em realidade concreta. ğŸš€

---

*Este documento foi criado como material educacional para o curso de Compiladores. Para dÃºvidas, sugestÃµes ou correÃ§Ãµes, consulte o repositÃ³rio principal.*
