
### üìå **1. Conceito de An√°lise L√©xica (Lexical Analysis)**

A **an√°lise l√©xica** √© a **primeira fase** de um compilador. Sua fun√ß√£o principal √© **ler a sequ√™ncia de caracteres de um programa-fonte** e **agrupar esses caracteres em unidades significativas chamadas *tokens***.

#### üí° O que s√£o *tokens*?

Um **token** representa uma **categoria de s√≠mbolo l√©xico**, ou seja, uma unidade b√°sica da linguagem de programa√ß√£o, como:

- **Palavras-chave**: `if`, `while`, `return`
- **Identificadores**: `x`, `total`, `soma_media`
- **Operadores**: `+`, `-`, `*`, `==`
- **Delimitadores**: `(`, `)`, `{`, `}`, `;`
- **Literais**: `123`, `3.14`, `'A'`, `"texto"`

---

### üìö **2. Fun√ß√µes da An√°lise L√©xica**

1. **Remover espa√ßos em branco e coment√°rios** irrelevantes para a sintaxe.
2. **Reconhecer padr√µes de tokens** usando express√µes regulares ou aut√¥matos.
3. **Informar erros l√©xicos**, como identificadores com caracteres inv√°lidos ou n√∫meros mal formados.
4. **Fornecer tokens para o analisador sint√°tico**, geralmente por meio de uma interface que permite o pr√≥ximo token (`get_next_token()`).

---

### üî† **3. Diferen√ßa entre s√≠mbolo, lexema e token**

| Termo     | Defini√ß√£o |
|-----------|-----------|
| **S√≠mbolo** | Um caractere individual da entrada (`a`, `1`, `=`) |
| **Lexema** | Uma sequ√™ncia concreta de caracteres (`int`, `x1`, `123`) |
| **Token** | A representa√ß√£o abstrata da categoria do lexema (`INT`, `IDENT`, `NUM`) |

Exemplo:

```c
int x = 10;
```

| Lexema | Token |
|--------|-------|
| `int`  | `KEYWORD_INT` |
| `x`    | `IDENTIFIER` |
| `=`    | `ASSIGN_OP` |
| `10`   | `NUMBER` |
| `;`    | `SEMICOLON` |

---

### ‚öôÔ∏è **4. Como funciona internamente?**

#### a) **Express√µes Regulares**

A linguagem l√©xica √© definida com **express√µes regulares**. Exemplos:

- Identificador: `[a-zA-Z_][a-zA-Z0-9_]*`
- N√∫mero inteiro: `[0-9]+`
- Espa√ßos: `[ \t\n]+`

#### b) **Aut√¥matos Finitos**

As express√µes regulares s√£o convertidas em **aut√¥matos finitos determin√≠sticos (DFA)** ou **n√£o determin√≠sticos (NFA)**, que s√£o usados para percorrer o texto e identificar os tokens.

---

### üß† **Import√¢ncia da An√°lise L√©xica**

- **Simplifica** o trabalho das fases posteriores, especialmente a an√°lise sint√°tica.
- **Garante a clareza** e robustez do processo de tradu√ß√£o.
- **Permite modulariza√ß√£o**, separando a l√≥gica de reconhecimento de s√≠mbolos da l√≥gica gramatical.

---


## üîç 5. **Etapas Internas da An√°lise L√©xica**

A an√°lise l√©xica pode ser dividida em v√°rias **subetapas** que ocorrem em sequ√™ncia ou paralelamente durante o processo de leitura do c√≥digo-fonte:

### 5.1. **Leitura de Caracteres**

A entrada √© lida caractere por caractere, muitas vezes usando um **buffer** para melhorar a performance. O analisador mant√©m ponteiros para indicar:

- In√≠cio do lexema atual.
- Posi√ß√£o do caractere que est√° sendo analisado no momento.

### 5.2. **Reconhecimento de Padr√µes**

O analisador tenta **casar a sequ√™ncia de caracteres lida com algum padr√£o definido** (geralmente via express√µes regulares). Exemplo:

- Se a entrada for `while`, o analisador tenta casar com o padr√£o de palavra-chave.

Se houver mais de um casamento poss√≠vel, geralmente se aplica a **regra do maior prefixo** (longest match rule) ‚Äî ou seja, escolhe-se o maior lexema poss√≠vel que forme um token v√°lido.

### 5.3. **Gera√ß√£o de Token**

Uma vez reconhecido o padr√£o, o analisador **cria um token**, que normalmente inclui:

- O **tipo do token** (ex: `IDENTIFIER`, `KEYWORD`, `NUMBER`, etc.)
- O **valor l√©xico** (ex: o nome da vari√°vel ou o valor num√©rico)
- Opcionalmente: posi√ß√£o no c√≥digo (linha, coluna)

### 5.4. **Tratamento de Erros L√©xicos**

Quando o analisador encontra uma sequ√™ncia inv√°lida (como `@x` ou `1var`), ele pode:

- Ignorar o caractere e seguir.
- Sinalizar o erro e tentar recupera√ß√£o.
- Parar a compila√ß√£o.

---

## ü§ñ 6. **Formalismo Matem√°tico: Linguagens Regulares**

Do ponto de vista te√≥rico, a an√°lise l√©xica trabalha com linguagens formais chamadas **linguagens regulares**, que s√£o aquelas que podem ser descritas por:

- **Express√µes regulares** (regex)
- **Aut√¥matos finitos determin√≠sticos (DFA)**
- **Aut√¥matos finitos n√£o determin√≠sticos (NFA)**

### Rela√ß√£o entre esses modelos:

- Toda **express√£o regular** pode ser transformada em um **NFA**.
- Todo **NFA** pode ser convertido em um **DFA**.
- Todo **DFA** pode ser **minimizado** para obter uma forma mais eficiente.

---

## üß∞ 7. **Ferramentas para An√°lise L√©xica**

Diversas ferramentas automatizam a constru√ß√£o do analisador l√©xico com base em express√µes regulares e regras definidas. Algumas delas:

### 7.1. **Lex (UNIX)**

Uma das ferramentas cl√°ssicas. Permite definir express√µes regulares e a√ß√µes em C. Usa-se com o `yacc` para an√°lise sint√°tica.

### 7.2. **Flex (Fast Lex)**

Vers√£o moderna do Lex, mais eficiente.

### 7.3. **PLY (Python Lex-Yacc)**

Biblioteca em Python que permite criar analisadores l√©xicos e sint√°ticos diretamente em c√≥digo Python.

Exemplo simples com `ply.lex`:

```python
import ply.lex as lex

tokens = ('NUMBER', 'PLUS')

t_PLUS = r'\+'
t_NUMBER = r'\d+'

t_ignore = ' \t'

def t_error(t):
    print(f"Caractere ilegal: {t.value[0]}")
    t.lexer.skip(1)

lexer = lex.lex()

lexer.input("3 + 42")

for tok in lexer:
    print(tok)
```

---

## üß† 8. **Desempenho e Otimiza√ß√µes**

- **Buffers duplos** s√£o usados para evitar o custo de I/O a cada caractere.
- **Tabela de s√≠mbolos l√©xicos** pode ser criada durante a an√°lise para armazenar identificadores, constantes, etc.
- **Caching e hashing** s√£o usados para melhorar a busca por lexemas em tokens j√° reconhecidos.

---

## üìå 9. **Resumo dos Pap√©is do Analisador L√©xico**

| Papel | Descri√ß√£o |
|-------|-----------|
| **Filtrar entrada** | Remove espa√ßos, tabula√ß√µes, quebras de linha, coment√°rios. |
| **Agrupar caracteres** | Identifica agrupamentos v√°lidos (tokens). |
| **Classificar tokens** | Atribui r√≥tulos de tipos de token. |
| **Manter posi√ß√£o** | Guarda linha e coluna para mensagens de erro. |
| **Reportar erros l√©xicos** | Detecta e sinaliza entradas malformadas. |

---

## üìò 10. **Refer√™ncias Cl√°ssicas e Acad√™micas**

### A. **Alfred V. Aho, Ravi Sethi, Jeffrey D. Ullman**
> Obra: *Compiladores ‚Äì Princ√≠pios, T√©cnicas e Ferramentas* (tamb√©m conhecido como "O Livro do Drag√£o").

Este √© o **livro-texto mais citado** na disciplina de compiladores. Os autores definem o processo de an√°lise l√©xica como:

> ‚ÄúA an√°lise l√©xica √© a fase do compilador respons√°vel por particionar a cadeia de entrada em unidades significativas chamadas tokens.‚Äù  
> ‚Äî Aho, Sethi, Ullman (1986)

Eles apresentam formalmente os **aut√¥matos finitos determin√≠sticos (DFA)** como estrutura b√°sica para reconhecimento eficiente de padr√µes l√©xicos. No cap√≠tulo de an√°lise l√©xica, os autores tamb√©m discutem a **tradu√ß√£o de express√µes regulares para aut√¥matos finitos**, com algoritmos formais para a constru√ß√£o do aut√¥mato a partir da regex (ex: *constru√ß√£o de Thompson*).

---

### B. **Andrew W. Appel**
> Obra: *Modern Compiler Implementation in Java / C / ML*

Appel enfatiza uma abordagem pr√°tica de constru√ß√£o de compiladores. Segundo ele:

> ‚ÄúO analisador l√©xico √© um filtro, uma fase que processa os dados da entrada com uma granularidade maior, preparando-os para an√°lise sint√°tica.‚Äù  
> ‚Äî Appel (1997)

Appel tamb√©m introduz o conceito de **geradores de analisadores l√©xicos** como ferramentas essenciais para engenheiros de compiladores, destacando a import√¢ncia de separar **an√°lise l√©xica (reconhecimento)** da **a√ß√£o sem√¢ntica (interpreta√ß√£o)**.

---

### C. **Kenneth C. Louden**
> Obra: *Compiler Construction: Principles and Practice*

Louden tem uma abordagem bem did√°tica. Ele explica o processo do scanner (analisador l√©xico) como:

> ‚ÄúO scanner √© respons√°vel por identificar os padr√µes l√©xicos, ignorar caracteres irrelevantes, e reconhecer erros primitivos no texto-fonte.‚Äù  
> ‚Äî Louden (1997)

Louden detalha implementa√ß√µes passo a passo de um analisador l√©xico usando C, incluindo t√©cnicas de *backtracking*, *lookahead*, e gerenciamento de erros.

---

## üìê 11. **Modelos Formais Aplicados na An√°lise L√©xica**

A teoria da computa√ß√£o serve como base s√≥lida para a an√°lise l√©xica:

### üß© Linguagens Regulares

A classe de linguagens reconhec√≠veis por **aut√¥matos finitos** √© exatamente a das **linguagens regulares**, que podem ser expressas por:

- Express√µes regulares (regex)
- Gram√°ticas regulares (tipo 3 na hierarquia de Chomsky)

A rela√ß√£o entre essas representa√ß√µes √© explorada por autores como:

- **Hopcroft, Motwani e Ullman**  
  > Obra: *Introduction to Automata Theory, Languages, and Computation*  
  Este livro √© refer√™ncia cl√°ssica para formalismos como DFA, NFA, express√µes regulares, e gram√°ticas.

---

## üß™ 12. **Reconhecimento de Tokens com Express√µes Regulares**

No processo de constru√ß√£o de um lexer, cada tipo de token √© definido por uma express√£o regular:

| Token       | Express√£o Regular            |
|-------------|------------------------------|
| Identificador | `[a-zA-Z_][a-zA-Z0-9_]*`    |
| N√∫mero inteiro | `[0-9]+`                  |
| Espa√ßos      | `[ \t\n\r]+`                |
| Operadores   | `\+|\-|\*|\/|==|=`           |

Estas express√µes s√£o **combinadas** em uma **√∫nica express√£o regular grande**, e um **aut√¥mato finito** correspondente √© criado para reconhecer os padr√µes.

---

## üîÑ 13. **Convers√£o de Regex ‚Üí NFA ‚Üí DFA**

### Constru√ß√£o de Thompson (Thompson's Construction):
√â um m√©todo sistem√°tico para transformar uma express√£o regular em um **NFA**. Em seguida, usa-se o **algoritmo de subconjuntos** para converter o NFA em um **DFA** equivalente (determin√≠stico), que √© mais eficiente em tempo de execu√ß√£o.

Depois, o DFA pode ser **minimizado** para melhorar ainda mais o desempenho.

---

## ‚ö†Ô∏è 14. **Tratamento de Erros L√©xicos**

A detec√ß√£o de erros l√©xicos ocorre quando uma sequ√™ncia de caracteres **n√£o corresponde a nenhum token v√°lido**.

Autores como Louden e Aho sugerem estrat√©gias como:

- **P√¢nico**: Ignorar o caractere ou grupo de caracteres at√© encontrar um separador como `;` ou `}`.
- **Corre√ß√£o de erros**: Tentar pequenas altera√ß√µes como substitui√ß√£o de um caractere (`=` no lugar de `==`), inser√ß√£o ou dele√ß√£o.

O objetivo √© **manter a compila√ß√£o prosseguindo** ao m√°ximo, fornecendo **diagn√≥sticos √∫teis** ao programador.

---

## üìä 15. **Tabela de S√≠mbolos e Tokens**

Durante a an√°lise l√©xica, √© comum usar uma **tabela de s√≠mbolos** para armazenar identificadores e literais (como strings e n√∫meros). Cada entrada na tabela inclui:

- Nome
- Tipo de dado
- Escopo (em fases posteriores)
- Endere√ßo na mem√≥ria (em fases de gera√ß√£o de c√≥digo)

Essa tabela pode ser implementada como uma **tabela hash**.

---

## üß† 16. **Resumo Conceitual (com autores)**

| Conceito                     | Defini√ß√£o | Autor |
|-----------------------------|-----------|-------|
| Token                       | Unidade b√°sica de significado l√©xico | Aho et al. |
| Lexema                      | Sequ√™ncia de caracteres que corresponde a um token | Aho et al. |
| Express√£o regular           | Representa√ß√£o de padr√µes lexicais | Hopcroft et al. |
| Aut√¥mato Finito Determin√≠stico | M√°quina de estados que reconhece tokens | Appel, Aho |
| Gerador l√©xico              | Ferramenta para criar analisadores l√©xicos | Louden |
| Tabela de s√≠mbolos          | Estrutura para armazenar informa√ß√µes de identificadores | Appel, Louden |

---

Claro, Luis! Vamos construir um exemplo simples de **analisador l√©xico (lexer) em C**, **sem usar ferramentas como Lex ou Flex**, para que possamos ver como √© o processo "na m√£o".

Esse analisador reconhecer√°:

- **Palavras-chave**: `if`, `else`, `while`, `return`
- **Identificadores**: letras seguidas de letras/d√≠gitos/underscore
- **N√∫meros inteiros**
- **S√≠mbolos**: `+`, `-`, `*`, `/`, `=`, `;`, `(`, `)`

---

## ‚úÖ Estrutura do Projeto

Vamos organizar o c√≥digo em um √∫nico arquivo `lexer.c` com fun√ß√µes b√°sicas de leitura e classifica√ß√£o de tokens.

---

## üßæ C√≥digo completo (lexer.c)

```c
#include <stdio.h>
#include <ctype.h>
#include <string.h>
#include <stdlib.h>

#define MAX_TOKEN_LENGTH 100

// Lista de palavras-chave
const char* keywords[] = {"if", "else", "while", "return"};
const int num_keywords = 4;

typedef enum {
    TOKEN_KEYWORD,
    TOKEN_IDENTIFIER,
    TOKEN_NUMBER,
    TOKEN_SYMBOL,
    TOKEN_UNKNOWN,
    TOKEN_EOF,
    TOKEN_STRING,
    TOKEN_COMMENT,
    TOKEN_CHAR,
    TOKEN_OPERATOR,
    TOKEN_PREPROCESSOR
} TokenType;

typedef struct {
    TokenType type;
    char lexeme[MAX_TOKEN_LENGTH];
} Token;

// Verifica se √© uma palavra-chave
// Esta fun√ß√£o recebe uma string e verifica se ela est√° na lista de palavras-chave.
// Retorna 1 se for uma palavra-chave, caso contr√°rio retorna 0.
int is_keyword(const char* str) {
    for (int i = 0; i < num_keywords; i++) {
        if (strcmp(str, keywords[i]) == 0) {
            return 1;
        }
    }
    return 0;
}

// L√™ o pr√≥ximo token do arquivo
// Esta fun√ß√£o analisa o arquivo caractere por caractere para identificar tokens.
// Ela reconhece diferentes tipos de tokens, como palavras-chave, identificadores, n√∫meros, strings, s√≠mbolos e coment√°rios.
// Retorna um token identificado.
Token get_next_token(FILE* fp) {
    char ch;
    Token token;
    int i = 0;

    // Pular espa√ßos em branco
    while ((ch = fgetc(fp)) != EOF && isspace(ch));

    // Verificar e ignorar coment√°rios
    if (ch == '/') {
        char next = fgetc(fp);
        if (next == '/') {
            // Coment√°rio de linha - ignora at√© o fim da linha
            while ((ch = fgetc(fp)) != EOF && ch != '\n');
            return get_next_token(fp); // chama recursivamente para buscar pr√≥ximo token
        } else if (next == '*') {
            // Coment√°rio de bloco - ignora at√© encontrar */
            char prev = 0;
            while ((ch = fgetc(fp)) != EOF) {
                if (prev == '*' && ch == '/') {
                    break;
                }
                prev = ch;
            }
            return get_next_token(fp); // continua buscando tokens
        } else {
            // N√£o era coment√°rio, √© divis√£o ou outro operador
            ungetc(next, fp);
        }
    }
    
    // String literal
    if (ch == '"') {
        token.type = TOKEN_STRING;
        i = 0;
        token.lexeme[i++] = ch; // abre aspas

        while ((ch = fgetc(fp)) != EOF) {
            token.lexeme[i++] = ch;

            if (ch == '\\') {
                // L√™ o caractere escapado (ex: \" ou \\)
                char esc = fgetc(fp);
                if (esc == EOF) break;
                token.lexeme[i++] = esc;
            } else if (ch == '"') {
                // Fechou a string
                break;
            }

            if (i >= MAX_TOKEN_LENGTH - 2) {
                printf("String muito longa!\n");
                exit(1);
            }
        }

        token.lexeme[i] = '\0';
        return token;
    }

    // Verifica se chegou ao final do arquivo
    if (ch == EOF) {
        token.type = TOKEN_EOF;
        strcpy(token.lexeme, "EOF");
        return token;
    }

    // Identificadores ou palavras-chave
    // Identifica palavras que come√ßam com letras ou '_'.
    // Verifica se √© uma palavra-chave ou um identificador.
    if (isalpha(ch) || ch == '_') {
        token.lexeme[i++] = ch;
        while ((ch = fgetc(fp)) != EOF && (isalnum(ch) || ch == '_')) {
            token.lexeme[i++] = ch;
        }
        token.lexeme[i] = '\0';
        ungetc(ch, fp); // devolve o √∫ltimo caractere lido

        if (is_keyword(token.lexeme)) {
            token.type = TOKEN_KEYWORD;
        } else {
            token.type = TOKEN_IDENTIFIER;
        }
        return token;
    }

    // N√∫meros
    // Identifica sequ√™ncias de d√≠gitos como n√∫meros.
    if (isdigit(ch)) {
        token.lexeme[i++] = ch;
        while ((ch = fgetc(fp)) != EOF && isdigit(ch)) {
            token.lexeme[i++] = ch;
        }
        token.lexeme[i] = '\0';
        ungetc(ch, fp);
        token.type = TOKEN_NUMBER;
        return token;
    }

    // S√≠mbolos simples
    // Identifica s√≠mbolos como operadores ou pontua√ß√µes.
    if (strchr("+-*/=;()", ch)) {
        token.lexeme[0] = ch;
        token.lexeme[1] = '\0';
        token.type = TOKEN_SYMBOL;
        return token;
    }

    // Token desconhecido
    // Caso nenhum dos casos anteriores seja atendido, o caractere √© considerado desconhecido.
    token.lexeme[0] = ch;
    token.lexeme[1] = '\0';
    token.type = TOKEN_UNKNOWN;
    return token;
}

// Converte o tipo de token para uma string
// Esta fun√ß√£o recebe um tipo de token e retorna uma string representando o tipo.
// √â √∫til para exibir os tokens de forma leg√≠vel.
const char* token_type_to_string(TokenType type) {
    switch (type) {
        case TOKEN_KEYWORD: return "KEYWORD";
        case TOKEN_IDENTIFIER: return "IDENTIFIER";
        case TOKEN_NUMBER: return "NUMBER";
        case TOKEN_SYMBOL: return "SYMBOL";
        case TOKEN_EOF: return "EOF";
        default: return "UNKNOWN";
    }
}

// Fun√ß√£o principal
// Abre o arquivo de entrada, l√™ os tokens usando `get_next_token` e os exibe no console.
// Fecha o arquivo ao final.
int main() {
    FILE* fp = fopen("entrada.txt", "r");
    if (!fp) {
        printf("Erro ao abrir arquivo.\n");
        return 1;
    }

    Token token;
    do {
        token = get_next_token(fp);
        printf("<%s, '%s'>\n", token_type_to_string(token.type), token.lexeme);
    } while (token.type != TOKEN_EOF);

    fclose(fp);
    return 0;
}
```

---

## üìù Exemplo de entrada (`entrada.txt`)

```c
if (x1 == 42) {
    return y + 5;
}
```

---

## üßæ Sa√≠da esperada

```bash
<KEYWORD, 'if'>
<SYMBOL, '('>
<IDENTIFIER, 'x1'>
<SYMBOL, '='>
<SYMBOL, '='>
<NUMBER, '42'>
<SYMBOL, ')'>
<KEYWORD, 'return'>
<IDENTIFIER, 'y'>
<SYMBOL, '+'>
<NUMBER, '5'>
<SYMBOL, ';'>
<SYMBOL, '}' >
<EOF, 'EOF'>
```

---

## üìå Observa√ß√µes

- O lexer lida apenas com **s√≠mbolos de um caractere** (ex: ele quebra `==` em dois `=`).
- Podemos expandir facilmente para s√≠mbolos compostos como `==`, `<=`, `!=` com **lookahead**.
- A fun√ß√£o `ungetc()` permite ‚Äúdevolver‚Äù um caractere para o fluxo de leitura.
- A estrutura √© ideal para fins educacionais, sendo totalmente customiz√°vel.

---

Boa pergunta, Luis! Reconhecer **operadores compostos** como `==`, `!=`, `<=`, `>=`, `&&`, `||` exige uma **leitura com *lookahead*** ‚Äî ou seja, ao ver um caractere como `=`, a gente precisa olhar o pr√≥ximo para decidir se √© `=` ou `==`.

Vou te mostrar isso na pr√°tica, adicionando esse recurso ao **analisador l√©xico em C** que te mostrei antes.

---

## ‚úÖ Operadores compostos que vamos reconhecer:

| Operador | Significado     |
|----------|-----------------|
| `==`     | Igualdade       |
| `!=`     | Diferente       |
| `<=`     | Menor ou igual  |
| `>=`     | Maior ou igual  |
| `&&`     | E l√≥gico        |
| `||`     | Ou l√≥gico       |
| `=`      | Atribui√ß√£o      |
| `<`, `>` | Relacionais     |

---

## üîß Ajuste na fun√ß√£o `get_next_token()`

Aqui est√° o trecho alterado da fun√ß√£o para suportar isso:

```c
// S√≠mbolos simples e compostos
if (strchr("=<>!&|", ch)) {
    char next = fgetc(fp);
    token.lexeme[0] = ch;
    token.lexeme[1] = '\0';

    // Compara operadores compostos
    if ((ch == '=' && next == '=') ||
        (ch == '!' && next == '=') ||
        (ch == '<' && next == '=') ||
        (ch == '>' && next == '=') ||
        (ch == '&' && next == '&') ||
        (ch == '|' && next == '|')) {
        token.lexeme[1] = next;
        token.lexeme[2] = '\0';
    } else {
        ungetc(next, fp); // n√£o era parte de operador composto
    }

    token.type = TOKEN_SYMBOL;
    return token;
}
```

### O que essa l√≥gica faz?

1. Se o caractere lido for `=`, `<`, `>`, `!`, `&` ou `|`, a gente suspeita que **pode ser um operador composto**.
2. Lemos o **pr√≥ximo caractere**.
3. Verificamos se o par forma um operador v√°lido.
4. Se n√£o formar, usamos `ungetc()` para devolver o caractere extra e ficamos com o s√≠mbolo simples.

---

## üß™ Exemplo: entrada de teste

```c
if (x1 != 42 && y >= 10 || z == 0) {
    x = 1;
}
```

### Sa√≠da esperada:

```bash
<KEYWORD, 'if'>
<SYMBOL, '('>
<IDENTIFIER, 'x1'>
<SYMBOL, '!='>
<NUMBER, '42'>
<SYMBOL, '&&'>
<IDENTIFIER, 'y'>
<SYMBOL, '>='>
<NUMBER, '10'>
<SYMBOL, '||'>
<IDENTIFIER, 'z'>
<SYMBOL, '=='>
<NUMBER, '0'>
<SYMBOL, ')'>
<SYMBOL, '{'>
<IDENTIFIER, 'x'>
<SYMBOL, '='>
<NUMBER, '1'>
<SYMBOL, ';'>
<SYMBOL, '}' >
<EOF, 'EOF'>
```

---

## üì¶ Dica b√¥nus: macro para facilitar compara√ß√£o

Voc√™ pode definir uma macro para simplificar a checagem:

```c
#define MATCH_COMPOSITE(op1, op2) (ch == op1 && next == op2)
```

E a√≠ no `if` usaria:

```c
if (MATCH_COMPOSITE('=', '=') || MATCH_COMPOSITE('!', '=') || 
    MATCH_COMPOSITE('<', '=') || MATCH_COMPOSITE('>', '=')) {
    // Operador composto encontrado
    token.lexeme[0] = ch;
    token.lexeme[1] = next;
    token.lexeme[2] = '\0';
    token.type = TOKEN_OPERATOR;
    fgetc(fp); // consome o segundo caractere
}
```

---

### Documenta√ß√£o do C√≥digo: exemploSimples.c


**Descri√ß√£o Geral**

Este c√≥digo implementa um analisador l√©xico simples que l√™ um arquivo de entrada (entrada.txt) e divide seu conte√∫do em tokens. Um token √© uma unidade b√°sica de uma linguagem, como palavras-chave, identificadores, n√∫meros, s√≠mbolos, etc. O programa processa o arquivo e imprime os tokens no formato <tipo, 'lexema'>, onde:

- **Tipo**: Categoria do token (ex.: palavra-chave, identificador, n√∫mero, etc.).   
- **Lexema**: O valor textual do token extra√≠do.


O analisador l√©xico tamb√©m reconhece e ignora coment√°rios (de linha e de bloco) e espa√ßos em branco.

---

#### **Estrutura do C√≥digo**

##### **1. Defini√ß√µes e Estruturas**

**Constantes**

```c
#define MAX_TOKEN_LENGTH 100
```

- Define o tamanho m√°ximo de um token (100 caracteres).

**Palavras-chave**

```c
const char* keywords[] = {"if", "else", "while", "return"};
const int num_keywords = 4;
```

- Lista de palavras-chave reconhecidas pelo analisador l√©xico.
- ```num_keywords``` define o n√∫mero de palavras-chave.

#### **Tipos de Tokens**

```c
typedef enum {
    TOKEN_KEYWORD,
    TOKEN_IDENTIFIER,
    TOKEN_NUMBER,
    TOKEN_SYMBOL,
    TOKEN_UNKNOWN,
    TOKEN_EOF,
    TOKEN_STRING,
    TOKEN_COMMENT,
    TOKEN_CHAR,
    TOKEN_OPERATOR,
    TOKEN_PREPROCESSOR
} TokenType;
```
-  Enumera√ß√£o que define os tipos de tokens que o analisador pode reconhecer.


#### **Estrutura do Token**

```c

typedef struct {
    TokenType type;
    char lexeme[MAX_TOKEN_LENGTH];
} Token;
```

- Representa um token com:
    - ```type```: O tipo do token (ex.: palavra-chave, identificador, etc.).
    - ```lexeme```: O valor textual do token.

---

#### **2. Fun√ß√µes Auxiliares**

**Verificar Palavras-Chave**

```c
int is_keyword(const char* str);
```

- Verifica se uma string √© uma palavra-chave.
- Retorna 1 se for uma palavra-chave, caso contr√°rio, retorna 0.


#### **3. Fun√ß√£o Principal: ```get_next_token```**

A fun√ß√£o ```get_next_token``` l√™ o pr√≥ximo token do arquivo e o classifica. Ela processa o arquivo caractere por caractere.

**Etapas da Fun√ß√£o**.  

**1. Ignorar Espa√ßos em Branco**
```c
while ((ch = fgetc(fp)) != EOF && isspace(ch));
```

- Ignora espa√ßos, tabula√ß√µes e quebras de linha.

**2. Ignorar Coment√°rios**

    - **Coment√°rios de Linha ()**:
```c
if (next == '/') {
    while ((ch = fgetc(fp)) != EOF && ch != '\n');
    return get_next_token(fp);
}
```

- Ignora o restante da linha ap√≥s .
- **Coment√°rios de Bloco (/* ... */):**
```c
if (next == '*') {
    char prev = 0;
    while ((ch = fgetc(fp)) != EOF) {
        if (prev == '*' && ch == '/') break;
        prev = ch;
    }
    return get_next_token(fp);
}
```

- Ignora tudo entre /* e */.
- 
**3. Reconhecer Strings Literais**

```c
if (ch == '"') {
    token.type = TOKEN_STRING;
    i = 0;
    token.lexeme[i++] = ch; // abre aspas
    
    while ((ch = fgetc(fp)) != EOF && ch != '"') {
        if (ch == '\\') {
            // Caractere escapado - l√™ o pr√≥ximo
            token.lexeme[i++] = ch;
            if ((ch = fgetc(fp)) != EOF) {
                token.lexeme[i++] = ch;
            }
        } else {
            token.lexeme[i++] = ch;
        }
    }
    
    if (ch == '"') {
        token.lexeme[i++] = ch; // fecha aspas
    }
    token.lexeme[i] = '\0';
}
```
- L√™ strings delimitadas por aspas ("), incluindo caracteres escapados (ex.: \").


**4. Reconhecer Identificadores e Palavras-Chave**
```c
if (isalpha(ch) || ch == '_') {
    i = 0;
    token.lexeme[i++] = ch;
    
    while ((ch = fgetc(fp)) != EOF && (isalnum(ch) || ch == '_')) {
        token.lexeme[i++] = ch;
    }
    
    token.lexeme[i] = '\0';
    ungetc(ch, fp); // devolve o √∫ltimo caractere lido
    
    if (is_keyword(token.lexeme)) {
        token.type = TOKEN_KEYWORD;
    } else {
        token.type = TOKEN_IDENTIFIER;
    }
}
```

- Identificadores come√ßam com letras ou _ e podem conter letras, n√∫meros ou _.
- Verifica se o identificador √© uma palavra-chave.

**5. Reconhecer N√∫meros**
```c
if (isdigit(ch)) {
    i = 0;
    token.lexeme[i++] = ch;
    
    while ((ch = fgetc(fp)) != EOF && isdigit(ch)) {
        token.lexeme[i++] = ch;
    }
    
    // Suporte para n√∫meros de ponto flutuante
    if (ch == '.') {
        token.lexeme[i++] = ch;
        while ((ch = fgetc(fp)) != EOF && isdigit(ch)) {
            token.lexeme[i++] = ch;
        }
    }
    
    token.lexeme[i] = '\0';
    ungetc(ch, fp); // devolve o √∫ltimo caractere lido
    token.type = TOKEN_NUMBER;
}
```
- L√™ sequ√™ncias de d√≠gitos como n√∫meros.

**6. Reconhecer S√≠mbolos**
```c
if (strchr("+-*/=;()", ch)) {
    i = 0;
    token.lexeme[i++] = ch;
    
    // Verifica operadores compostos (==, !=, <=, >=)
    if (ch == '=' || ch == '!' || ch == '<' || ch == '>') {
        char next = fgetc(fp);
        if (next == '=') {
            token.lexeme[i++] = next;
        } else {
            ungetc(next, fp);
        }
    }
    
    token.lexeme[i] = '\0';
    token.type = TOKEN_SYMBOL;
}
```

- Reconhece s√≠mbolos simples como +, -, *, /, =, ;, (, ).

**7. Token Desconhecido**

```c
token.type = TOKEN_UNKNOWN;
```

- Classifica caracteres n√£o reconhecidos como TOKEN_UNKNOWN.

**8. Fim do Arquivo**
```C
if (ch == EOF) {
    token.type = TOKEN_EOF;
    strcpy(token.lexeme, "EOF");
}
```

- Retorna o token TOKEN_EOF ao atingir o final do arquivo.

#### **4. Fun√ß√£o token_type_to_string**

```c
const char* token_type_to_string(TokenType type);
```

- Converte o tipo do token (TokenType) para uma string leg√≠vel.
- Exemplo:
    - ```TOKEN_KEYWORD ‚Üí "KEYWORD"```
    - ```TOKEN_IDENTIFIER ‚Üí "IDENTIFIER"```

#### **5. Fun√ß√£o ```main```**
A fun√ß√£o principal executa o analisador l√©xico.

#### **Etapas**

**1. Abrir o Arquivo**

```c
FILE* fp = fopen("entrada.txt", "r");
if (!fp) {
    printf("Erro ao abrir arquivo.\n");
    return 1;
}
```

- Abre o arquivo entrada.txt no modo de leitura.
- Exibe uma mensagem de erro e encerra o programa se o arquivo n√£o puder ser aberto.

**2. Processar Tokens**
```c
do {
    token = get_next_token(fp);
    printf("<%s, '%s'>\n", token_type_to_string(token.type), token.lexeme);
} while (token.type != TOKEN_EOF);
```

- L√™ tokens do arquivo usando get_next_token.
- Imprime cada token no formato <tipo, 'lexema'>.
- Continua at√© encontrar o token TOKEN_EOF.

**3. Fechar o Arquivo**
```c
fclose(fp);
```

- Fecha o arquivo ap√≥s o processamento.

**4. Encerrar o Programa**
```c
return 0;
```

- Retorna 0 para indicar que o programa foi executado com sucesso.


### **Exemplo de Entrada e Sa√≠da**

#### **Entrada (```entrada.txt```)**

```c
if (x == 10) {
    // Este √© um coment√°rio
    return x + 1;
}
```

**Sa√≠da**

```c
<KEYWORD, 'if'>
<SYMBOL, '('>
<IDENTIFIER, 'x'>
<SYMBOL, '=='>
<NUMBER, '10'>
<SYMBOL, ')'>
<SYMBOL, '{'>
<KEYWORD, 'return'>
<IDENTIFIER, 'x'>
<SYMBOL, '+'>
<NUMBER, '1'>
<SYMBOL, '}'>
<EOF, 'EOF'>
```

**Resumo**

Este c√≥digo implementa um analisador l√©xico simples que:

1. L√™ um arquivo de entrada.
2. Divide o conte√∫do em tokens.
3. Classifica os tokens em categorias como palavras-chave, identificadores, n√∫meros, s√≠mbolos, etc.
4. Ignora espa√ßos em branco e coment√°rios.
5. Imprime os tokens no formato ```<tipo, 'lexema'>```.

O analisador √© uma base para a constru√ß√£o de compiladores ou interpretadores, onde a an√°lise l√©xica √© o primeiro passo no processamento de c√≥digo-fonte.
